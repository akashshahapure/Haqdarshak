{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeeafe-6692-4696-89b0-ee742f7d58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python.exe -m pip install --upgrade pip\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install openpyxl\n",
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c70450f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\akash\\appdata\\roaming\\python\\python311\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\akash\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\akash\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\akash\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\akash\\appdata\\roaming\\python\\python311\\site-packages (1.25.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in c:\\program files\\python311\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\program files\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "*****Required libraries imported*****\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"\\n*****Required libraries imported*****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a1231-0b81-46fe-a7b0-5d62282e72c2",
   "metadata": {},
   "source": [
    "# Mention project raw data filename below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df8b1bf2-6d57-4b67-8e2d-3dafaf322fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide PID of project =  PID/TATAP/2023/DI/0335\n"
     ]
    }
   ],
   "source": [
    "file_Name = 'cases_report_Tata Power - Prayagraj_all_(All States)_2023-12-29.csv'\n",
    "\n",
    "# Asking for project ID from the user\n",
    "#PID = input('Please provide PID of project = ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "715f9235-c2e3-4b0e-91a1-20c59ea00048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvORexcel():\n",
    "    try:\n",
    "        path = \"C:\\\\Python\\\\read\\\\\"+file_Name\n",
    "        if file_Name.split('.')[-1].startswith('c'):\n",
    "            df = pd.read_csv(path)\n",
    "            return df\n",
    "        elif file_Name.split('.')[-1].startswith('x'):\n",
    "            df = pd.read_excel(path)\n",
    "            return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file name {0} has not found\".format(path))\n",
    "\n",
    "fn = file_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0a370c-132a-4494-8073-ea317ebc0f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csvORexcel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data0 \u001b[38;5;241m=\u001b[39m \u001b[43mcsvORexcel\u001b[49m()\n\u001b[0;32m      2\u001b[0m data0\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csvORexcel' is not defined"
     ]
    }
   ],
   "source": [
    "data0 = csvORexcel()\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a85c7-f853-4fc1-8fca-780a687c20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {'AP':'Andhra Pradesh',\n",
    "'AR':'Arunachal Pradesh',\n",
    "'AS':'Assam',\n",
    "'BR':'Bihar',\n",
    "'CT':'Chhattisgarh',\n",
    "'GA':'Goa',\n",
    "'GJ':'Gujarat',\n",
    "'HR':'Haryana',\n",
    "'HP':'Himachal Pradesh',\n",
    "'JH':'Jharkhand',\n",
    "'KA':'Karnataka',\n",
    "'KL':'Kerala',\n",
    "'MP':'Madhya Pradesh',\n",
    "'MH':'Maharashtra',\n",
    "'MN':'Manipur',\n",
    "'ML':'Meghalaya',\n",
    "'MZ':'Mizoram',\n",
    "'NL':'Nagaland',\n",
    "'OR':'Odisha',\n",
    "'PB':'Punjab',\n",
    "'RJ':'Rajasthan',\n",
    "'SK':'Sikkim',\n",
    "'TN':'Tamil Nadu',\n",
    "'TG':'Telangana',\n",
    "'TR':'Tripura',\n",
    "'UP':'Uttar Pradesh',\n",
    "'UT':'Uttarakhand',\n",
    "'WB':'West Bengal'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349775e-569b-4641-a2be-1cbed0404615",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98da0ce-4f2b-4e37-af8c-247a701e09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last row.\n",
    "data0.drop(index = data0[data0.Createdon.isna()].index, inplace=True)\n",
    "\n",
    "# Replace null values\n",
    "data0['Scheme/Doc'].fillna('a', inplace=True)\n",
    "data0['Citizen Name'].fillna('a', inplace=True)\n",
    "data0['HD Name'].fillna('blank', inplace=True)\n",
    "data0.Mobile.fillna(0, inplace=True)\n",
    "\n",
    "# Changing status values and keeping only \"Open/Submit/BR\"\n",
    "data0['Status'] = data0['Status'].apply(lambda x: 'Open' if x == 'Data complete' else 'Submitted' if (x=='Docket submitted' or x=='Document ready') else \"Benefit Received\" if x=='Scheme/Document received' else x)\n",
    "\n",
    "# Changing Case Organization values from state initials to full state name.\n",
    "data0['Case Organization'] = data0['Case Organization'].apply(lambda x: states[x[:2]])\n",
    "\n",
    "# Renaming column \"Case Organiisation\" & \"Case District\" to \"State\" & \"Disctrict\"\n",
    "data0.rename(columns={\"Case Organization\":\"State\",\"Case District\":\"District\"}, inplace=True)\n",
    "\n",
    "# Convert Mobile column from float to string for concatenation.\n",
    "data0['Mobile'] = data0['Mobile'].apply(lambda x: str(x).strip())\n",
    "#data0['Mobile'] = data0['Mobile'].astype('int64')\n",
    "data0['Mobile'] = data0['Mobile'].astype('str')\n",
    "\n",
    "# Change gender from initial letter to full form.\n",
    "data0['Gender'] = data0['Gender'].apply(lambda x: 'Male' if x=='M' else 'Female' if x=='F' else 'Other' if x=='O' else x)\n",
    "\n",
    "# Convert \"Createdon\", \"Docket Submitted Date\", \"Benefit received Date\" column data type to Datetime format\n",
    "dt_col = ['Createdon', 'Docket Submitted Date', 'Benefit received Date', 'DOB']\n",
    "\n",
    "for col in dt_col:\n",
    "    try:\n",
    "        data0[col] = pd.to_datetime(data0[col], format='mixed', errors='ignore')\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "# Deleting records with status \"Case Aborted\" and \"Application rejected\"\n",
    "data0 = data0[(data0['Status'] != 'Case Aborted') & (data0['Status'] != 'Application rejected')]\n",
    "rejectedDF = data0[(data0.Status == 'Case Aborted') | (data0.Status == 'Application rejected')] # Storing prev step deleted data\n",
    "\n",
    "data0.reset_index(inplace=True, drop=True)\n",
    "data0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046dc30-1f4b-4300-9650-b1058aea4172",
   "metadata": {},
   "source": [
    "# Translate local language district name to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcc080-8375-4d8b-9271-7aeec6443f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Case District name from local language to english\n",
    "\n",
    "data0['District'] = data0['District'].apply(lambda x: \"Dohad\" if x==\"દોહદ\" else \"Haridwar\" if x==\"हरिद्वार\" else \"UDHAM SINGH NAGAR\".title() if (x==\"उदम सिंह नगर\" or x==\"Udam Singh Nagar\" or x==\"UDAM SINGH NAGAR\")\n",
    "                             else \"Sitamarhi\" if x==\"सीतामढ़ी\" else \"Mahasamund\" if (x==\"महासमुंद\" or x==\"Mahasamand\")\n",
    "                             else \"Rajgarh\" if x==\"राजगढ़\" else \"Muzaffarpur\" if x==\"मुजफ्फरपुर\" else \"Nawada\" if x==\"नवादा\" else \"Balrampur\" if x==\"बलरामपुर\"\n",
    "                             else \"DAMOH\".title() if x==\"दमोह\" else \"Shravasti\" if x==\"श्रावस्ती\" else \"NARMADA\".title() if x==\"નર્મદા\" else \"Chhatarpur\" if (x==\"छतरपुर\" or x==\"Chhattarpur\")\n",
    "                             else 'East Singhbum' if x=='ईस्ट सिंघबम' else 'Chhindwara' if x=='छिंदवारा' else 'Jalna' if x=='जालना' else 'Dhule' if x=='धुळे' else \"Dhanbad\" if x==\"धनबाद\"\n",
    "                             else 'Banas Kantha' if x=='બનાસ કાંઠા' else 'Dhamtari' if x=='धमतरी' else 'Bilaspur' if x=='बिलासपुर' else x.title())\n",
    "\n",
    "data0['District'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a79754-1c19-4908-9340-56c4a73452cf",
   "metadata": {},
   "source": [
    "# Mention orgwise scheme applied raw data filename below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1798acf-fde1-4fe6-850d-549e436a4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_Name = 'orgwise_schemes_applied_2024-03-11T10_53_25.823048+05_30.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052ab6c-bce1-48aa-9145-4966e4a7faf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Schemes data from Orgwise schemes applied report\n",
    "schemeDetails = csvORexcel()\n",
    "#schemeDetails = schemeDetails[schemeDetails['Project Id']==PID.strip()]\n",
    "schemeDetails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca710be9-cb08-4506-84a0-6ea518e604a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing colomuns except 'Scheme Id','Scheme type','Benefit Value' to merge with main dataframe\n",
    "for s in schemeDetails.columns:\n",
    "    if s not in ['Scheme Id','Scheme type','Benefit Value','Received','Fee','Timeline']:\n",
    "        schemeDetails.drop(columns=s, inplace=True)\n",
    "\n",
    "# Merging scheme details with main dataframe for get data of Scheme type & Benefit Value.\n",
    "data0 = data0.merge(schemeDetails.drop_duplicates(subset=['Scheme Id']), left_on='Scheme/Doc GUID', right_on=\"Scheme Id\", how='left')\n",
    "\n",
    "# Removing non required column \"Scheme ID\"\n",
    "data0.drop(columns = 'Scheme Id', inplace=True)\n",
    "\n",
    "# Changing short form to \"Scheme\" & \"Document\"\n",
    "data0['Scheme type'] = data0['Scheme type'].apply(lambda x: 'Scheme' if x=='sch' else 'Document' if x=='doc' else x)\n",
    "\n",
    "# Converting \"Fee\" & \"Benefit Value\" columns to integer type\n",
    "data0.Fee.fillna(0.0, inplace=True)\n",
    "data0.Fee = data0.Fee.apply(lambda x: int(x))\n",
    "data0['Benefit Value'].fillna('0', inplace=True)\n",
    "data0['Benefit Value'] = data0['Benefit Value'].apply(lambda x: int(x))\n",
    "data0.Fee = data0.Fee.astype('int64')\n",
    "data0['Benefit Value'] = data0['Benefit Value'].astype('int64')\n",
    "\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fe7ac-12a7-43ab-9bca-2dfb67ccfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if number of data point has increased or not\n",
    "data0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85104d0f-88dc-493e-bc3e-a57fa123f565",
   "metadata": {},
   "source": [
    "# DFL Schemes\n",
    "\n",
    "- SH0009SW = Digital productivity Service_ Basic\n",
    "- SH000BM6 = Digital productivity Service_Basic\n",
    "- SH000AG6 = Digital Productivity Services_Advanced\n",
    "- SH000A32 = Long Training on Digital & Financial Inclusion_Private\n",
    "- SH0009SW = Short Training on Digital & Financial Inclusion_Private\n",
    "- SH000AG6 = Digital Productivity Services and and employability training_Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad19dc-2caa-469c-bce0-63fe6a5ac677",
   "metadata": {},
   "source": [
    "# Removing DFL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b30c6-8eac-44f0-9aa7-ea2b6fa32f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column \"Scheme Type\" to differentiate Schemes and DFL\n",
    "data0[\"Scheme Category\"] = data0['Scheme/Doc GUID'].apply(lambda x: \"DFL\" if (x==\"SH0009SW\" or x==\"SH000AG6\" or x==\"SH000A32\" or x==\"SH0009SW\" or x==\"SH000AG6\" or x==\"SH000BM6\") else \"E-Gov\")\n",
    "\n",
    "dfl = data0[(data0['Scheme/Doc GUID'] == 'SH0009SW') | (data0['Scheme/Doc GUID'] == 'SH000AG6') | (data0['Scheme/Doc GUID'] == 'SH000A32') | (data0['Scheme/Doc GUID']=='SH0009SW') | (data0['Scheme/Doc GUID']=='SH000AG6') | (data0['Scheme/Doc GUID']=='SH000BM6')]\n",
    "data0 = data0[(data0['Scheme/Doc GUID'] != 'SH0009SW') & (data0['Scheme/Doc GUID'] != 'SH000AG6') & (data0['Scheme/Doc GUID'] != 'SH000A32') & (data0['Scheme/Doc GUID']!='SH0009SW') & (data0['Scheme/Doc GUID']!='SH000AG6') & (data0['Scheme/Doc GUID']!='SH000BM6')]\n",
    "print(\"DFL Count={0}\\nE-Gov Count={1}\".format(len(dfl),len(data0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bf991-440a-473b-9c7c-40b2d0dc7ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data0.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be27e228-a74a-4925-b6b5-bd0ed4a963da",
   "metadata": {},
   "source": [
    "# Replace null values for all columns\n",
    "for i in data0.columns:\n",
    "    if data0[i].dtype == 'float64':\n",
    "        data0[i].fillna(0.0, inplace=True)\n",
    "    elif data0[i].dtype == 'int64':\n",
    "        data0[i].fillna(0, inplace=True)\n",
    "    else:\n",
    "        data0[i].fillna('a', inplace=True)\n",
    "\n",
    "# Note : This step has been skipped because Dtype of the columns also changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd755cd-950a-4ed3-aa35-604942da7883",
   "metadata": {},
   "source": [
    "# Duplicate Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84edf59d-1a9b-44a3-8bd9-f6a7f57d1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column with name 'duplicate' by concatenation\n",
    "data0['duplicate'] = data0['Scheme/Doc'] + data0['Citizen Name'] + data0['Mobile'] # Concatenation\n",
    "dfl['duplicate'] = dfl['Scheme/Doc'] + dfl['Citizen Name'] + dfl['Mobile']\n",
    "data0['duplicate'] = data0['duplicate'].apply(lambda x: x.lower()) # Converting duplicate column in lower case because python considers ASCII values of each character while checking for duplicates.\n",
    "dfl['duplicate'] = dfl['duplicate'].apply(lambda x: x.lower())\n",
    "data0.Mobile = data0.Mobile.apply(lambda x : int(x.split('.')[0])) # Converting \"Mobile\" column to interget data type\n",
    "dfl.Mobile = dfl.Mobile.apply(lambda x : int(x.split('.')[0])) # Converting \"Mobile\" column to interget data type\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e15d03-7854-43cb-9bc6-f6ae9d43942f",
   "metadata": {},
   "source": [
    "# Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f27b1-dbdd-41da-9647-88a044b9f98d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking number of all duplicate records\n",
    "duplicateData = data0[data0.duplicated(['duplicate'],keep=False)].sort_values('duplicate')\n",
    "dflDuplicates = dfl[dfl.duplicated(['duplicate'],keep=False)].sort_values('duplicate')\n",
    "pd.concat([duplicateData,dflDuplicates])\n",
    "duplicateData.reset_index(inplace=True, drop = True)\n",
    "\n",
    "try:\n",
    "    duplicateData.drop(index=duplicateData.index[-1], inplace=True)\n",
    "except IndexError:\n",
    "    print(duplicateData.shape)\n",
    "\n",
    "duplicateData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d6cfe-660a-4c1f-948b-b3699c2f9dc3",
   "metadata": {},
   "source": [
    "# Unique Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816c5f6-c4df-4264-8e6f-341f1d79209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping uniques excluding duplicates\n",
    "unique_data = data0.drop(index = data0[data0.duplicated(['duplicate'], keep='last')].index)\n",
    "unique_data.reset_index(inplace=True, drop = True)\n",
    "try:\n",
    "    unique_data.drop(index=unique_data.index[-1], inplace=True)\n",
    "except IndexError:\n",
    "    print(unique_data.shape)\n",
    "except:\n",
    "    unique_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413ad9b-7438-444c-ace9-a543119a41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating table citizen to scheme ratio.\n",
    "cit_sch_ratio = pd.DataFrame(unique_data['Citizen GUID'].value_counts())\n",
    "cit_sch_ratio.rename(columns={'count':'No of cases'}, inplace=True)\n",
    "cit_sch_ratio.reset_index(inplace=True)\n",
    "cit_sch_ratio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71c8f3-50ab-48ef-8114-b0cc37ec8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging no of cases with main project data.\n",
    "unique_data = unique_data.merge(cit_sch_ratio.drop_duplicates(subset=['Citizen GUID']), on = 'Citizen GUID', how = 'left')\n",
    "unique_data['No of cases'].fillna(0.0, inplace=True)\n",
    "unique_data['No of cases'] = unique_data['No of cases'].astype('int64')\n",
    "unique_data.reset_index(inplace=True, drop = True)\n",
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd86569-d2e5-4b3f-b947-306696178159",
   "metadata": {},
   "source": [
    "# Project wise O / S / BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f9750-5d7b-48ea-b80e-50d1d545a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing status values to O_S_BR\n",
    "projectwise_O_S_BR = pd.DataFrame(unique_data.Status.value_counts())\n",
    "projectwise_O_S_BR.rename(columns={'count':'Count of Application'}, inplace=True)\n",
    "projectwise_O_S_BR.reset_index(inplace=True)\n",
    "projectwise_O_S_BR.loc[len(projectwise_O_S_BR.index)] = ['Grand Total', projectwise_O_S_BR['Count of Application'].sum()]\n",
    "projectwise_O_S_BR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7cc50-bd32-4d4e-ac90-8fa036b8a6d9",
   "metadata": {},
   "source": [
    "# Districtwise Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d309823d-2874-494b-b15e-556ae4b2c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "districtWise = unique_data.pivot_table(index='District', values='Case Id', aggfunc='count').sort_values('Case Id', ascending=False).reset_index()\n",
    "districtWise.loc[len(districtWise)] = ['Grand Total',districtWise['Case Id'].sum()]\n",
    "districtWise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c7076-00cf-43bf-b544-c60985cfa170",
   "metadata": {},
   "source": [
    "# Orgwise Scheme Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67899d1f-41b9-4a97-b69e-db469e393fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orgSchDiver = unique_data.pivot_table(index=['State','Scheme/Doc'], values='Case Id', aggfunc='count') # Pivoting unique data with \"Case Organization\" & \"Scheme/Doc\" rows and count of column \"Case Id\"\n",
    "orgSchDiver.reset_index(inplace=True)\n",
    "Orgwise_Scheme_Diversity = pd.DataFrame(orgSchDiver['State'].value_counts()).reset_index().rename(columns={'count':'Count of unique schemes'}).sort_values('State') # Converting pivot table to pandas data frame\n",
    "Orgwise_Scheme_Diversity['Total Applications'] = orgSchDiver.groupby(by = 'State')['Case Id'].sum().values # Adding \"Total no. of cases\" column\n",
    "\n",
    "'''# 18-35 - DFL Advance/Basic BR\n",
    "digital_Adult = unique_data[(unique_data['Age'] >= 18) & (unique_data['Age'] <= 35) & (unique_data['Status'] == 'Benefit Received')]\n",
    "digital_Adult = pd.pivot_table(data=digital_Adult, index = 'Scheme/Doc', values = 'Case Id', aggfunc='count').reset_index()\n",
    "try:\n",
    "    Orgwise_Scheme_Diversity['18-35 - DFL Advance/Basic BR'] = digital_Adult[(digital_Adult['Scheme/Doc'] == 'Digital productivity Service_ Basic') |\n",
    "                                                                         (digital_Adult['Scheme/Doc'] == 'Digital Productivity Services_Advanced')].sum()[1]\n",
    "except IndexError:\n",
    "    Orgwise_Scheme_Diversity['18-35 - DFL Advance/Basic BR'] = digital_Adult[(digital_Adult['Scheme/Doc'] == 'Digital productivity Service_ Basic') |\n",
    "                                                                         (digital_Adult['Scheme/Doc'] == 'Digital Productivity Services_Advanced')].sum()[0]'''\n",
    "\n",
    "# Shcemes with more than 10% application\n",
    "orgDict = {} # Declaring a empty dictionary to store Shcemes with more than 10% application\n",
    "for org in Orgwise_Scheme_Diversity['State']:\n",
    "    maxApp = pd.DataFrame(orgSchDiver[orgSchDiver['State'] == org].groupby('Scheme/Doc')['Case Id'].sum()\n",
    "                          >\n",
    "                          int(orgSchDiver[orgSchDiver['State'] == org]['Case Id'].sum()/10)) # Getting list of more then 10% application\n",
    "    orgDict[org] = list(maxApp[maxApp['Case Id'] == True].index)\n",
    "Orgwise_Scheme_Diversity['Shcemes with more than 10% application'] = orgDict.values() # Adding \"Shcemes with more than 10% application\" column\n",
    "\n",
    "Orgwise_Scheme_Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5d3a0-d143-41c0-9f90-08512799c0c9",
   "metadata": {},
   "source": [
    "# Citizen Scheme Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27dde4-5a01-4d9a-ab64-126701330aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheme variety wise application ratio\n",
    "cit_sch_ratio = {'Scheme Variety':[],\n",
    "                 'Total Citizens':[],\n",
    "                 'Total Cases':[]}\n",
    "\n",
    "no_of_cases = list(set(unique_data['No of cases'].value_counts().index))\n",
    "no_of_case = []\n",
    "no_of_cit = []\n",
    "for n in no_of_cases:\n",
    "    if n == 0:\n",
    "        unique_data.drop(index=(unique_data[unique_data['No of cases'] == n].index), inplace=True)\n",
    "    \n",
    "    elif n>0 and n<=3:\n",
    "        cit_sch_ratio['Scheme Variety'].append('With {0} scheme'.format(n))\n",
    "        cit_sch_ratio['Total Citizens'].append(len(unique_data[unique_data['No of cases'] == n]['Citizen GUID'].value_counts()))\n",
    "        cit_sch_ratio['Total Cases'].append(len(unique_data[unique_data['No of cases'] == n]))\n",
    "    \n",
    "    elif n>3:\n",
    "        if 'More than 3 schemes' in cit_sch_ratio['Scheme Variety']:\n",
    "            no_of_case.append(len(unique_data[unique_data['No of cases'] == n]))\n",
    "            no_of_cit.append(len(unique_data[unique_data['No of cases'] == n]['Citizen GUID'].value_counts()))\n",
    "            \n",
    "        else:\n",
    "            cit_sch_ratio['Scheme Variety'].append('More than 3 schemes')\n",
    "            no_of_case.append(len(unique_data[unique_data['No of cases'] == n]))\n",
    "            no_of_cit.append(len(unique_data[unique_data['No of cases'] == n]['Citizen GUID'].value_counts()))\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Adding sum of cases and citizens against \"More than 3 schemes\"\n",
    "if n>3:\n",
    "    cit_sch_ratio['Total Cases'].append(sum(no_of_case))\n",
    "    cit_sch_ratio['Total Citizens'].append(sum(no_of_cit))\n",
    "\n",
    "# Grand Total\n",
    "cit_sch_ratio['Scheme Variety'].append('Grand Total')\n",
    "cit_sch_ratio['Total Citizens'].append(sum(cit_sch_ratio['Total Citizens']))\n",
    "cit_sch_ratio['Total Cases'].append(sum(cit_sch_ratio['Total Cases']))\n",
    "\n",
    "# More than 7 schemes\n",
    "cit_sch_ratio['Scheme Variety'].append('More than 7 schemes')\n",
    "cit_sch_ratio['Total Cases'].append(len(unique_data[unique_data['No of cases'] >= 7]))\n",
    "cit_sch_ratio['Total Citizens'].append(len(unique_data[unique_data['No of cases'] >= 7]['Citizen GUID'].value_counts()))\n",
    "\n",
    "cit_sch_ratio = pd.DataFrame(cit_sch_ratio)\n",
    "cit_sch_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc8458-79a6-4188-b633-179196393573",
   "metadata": {},
   "source": [
    "# Scheme Doc Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6f501-2fb8-4e86-9687-ca47ea63e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheme type Total application\n",
    "sch_doc_application = pd.DataFrame(unique_data.groupby(by = 'Scheme type')['Scheme/Doc'].count()).reset_index()\n",
    "sch_doc_application.rename(columns={'Scheme/Doc' : 'Total Applications'}, inplace=True)\n",
    "\n",
    "# Scheme type Total Benefit value\n",
    "sch_doc_application['Total BV'] = list(unique_data.groupby(by ='Scheme type')['Benefit Value'].sum())\n",
    "\n",
    "# Scheme type Total unique schemes\n",
    "sch_doc_schemes = pd.DataFrame(unique_data.groupby(by = 'Scheme type')['Scheme/Doc'].value_counts()).reset_index().drop(columns='count')\n",
    "sch_doc_schemes = pd.DataFrame(sch_doc_schemes.groupby(by='Scheme type')['Scheme/Doc'].count()).reset_index()\n",
    "sch_doc_schemes.rename(columns={'Scheme/Doc' : 'Unique Schemes'}, inplace=True)\n",
    "\n",
    "# Merging both tables\n",
    "sch_doc_ratio = sch_doc_schemes.merge(sch_doc_application, on = 'Scheme type', how = 'left')\n",
    "sch_doc_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f7f7f-b74e-4998-a558-34ea17010665",
   "metadata": {},
   "source": [
    "# Top Bottom HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a0dbc-79ae-4ee2-aece-8a3d609ee82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = unique_data.copy() # Copying data to another variable to make some changes.\n",
    "step['HD ID'] = step['HD ID'].fillna('a') # Replacing missing values with simple character 'a'\n",
    "step['HD ID'] = step['HD ID'].astype('str') # Changing HD ID column data type to string so that all values can be converted to lower case.\n",
    "step['HD ID'] = step['HD ID'].apply(lambda x: x.lower()) # Changing values to lower case.\n",
    "step1 = pd.pivot_table(data = step, index = ['HD ID', 'HD Name','Scheme/Doc GUID'], values = 'Case Id', aggfunc = 'count') # Pivoting to get unique HD ID/ HD Name/ Scheme Name\n",
    "step1 = pd.DataFrame(step1.drop(columns='Case Id').reset_index()) # Delete unwanted column 'Case Id'\n",
    "step1 = pd.DataFrame(pd.pivot_table(data=step1, index=['HD ID','HD Name'], values='Scheme/Doc GUID', aggfunc='count').reset_index()).rename(columns={'Scheme/Doc GUID' : 'Total unique schemes'}) # Pivoting to get unique HD ID/ HD Name and unique count of schemes.\n",
    "step2 = pd.DataFrame(step.groupby(by = 'HD ID')['Case Id'].count()).reset_index().rename(columns={'Case Id' : 'Total Applications'})\n",
    "step3 = step.groupby('HD ID')['Benefit Value'].sum().reset_index()\n",
    "top_bottom_hd = step1.merge(step2, on = 'HD ID', how='left').merge(step3, on = 'HD ID', how='left')\n",
    "top_bottom_hd.rename(columns={'Benefit Value':'Benefit Value Delivered'}, inplace=True)\n",
    "top_bottom_hd.loc[len(top_bottom_hd)] = ['Grand Total', '', top_bottom_hd['Total unique schemes'].sum(),\n",
    "                                         top_bottom_hd['Total Applications'].sum(), top_bottom_hd['Benefit Value Delivered'].sum()]\n",
    "top_bottom_hd.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5cdc7d-cefe-4d5a-9893-d5a480383ba6",
   "metadata": {},
   "source": [
    "# Scheme Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556250b-d1fd-4f57-944e-f3a244ce7fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Scheme_Categorisation = pd.DataFrame(pd.pivot_table(data = unique_data, index=['Scheme type', 'Scheme/Doc', 'Benefit Value'], values='Case Id', aggfunc= 'count')).reset_index()\n",
    "Scheme_Categorisation['Total BV Delivered'] = Scheme_Categorisation['Benefit Value']*Scheme_Categorisation['Case Id']\n",
    "Scheme_Categorisation.rename(columns={'Case Id':'Total Applications'}, inplace=True)\n",
    "Scheme_Categorisation.loc[len(Scheme_Categorisation)] = ['Grand Total', '', '', Scheme_Categorisation['Total Applications'].sum(), Scheme_Categorisation['Total BV Delivered'].sum()]\n",
    "Scheme_Categorisation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42524ff0-3a81-410e-b3ca-e7ae6e37f150",
   "metadata": {},
   "source": [
    "# Gender Bifurcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462b74b-c126-472f-9f0b-cd67d2f3abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_Bif = pd.DataFrame(unique_data['Gender'].value_counts()).reset_index()\n",
    "gen_Bif['% Contri.'] = round((gen_Bif['count']/unique_data['Gender'].value_counts().sum())*100,2)\n",
    "gen_Bif.rename(columns={'count':'Total Applications'},inplace=True)\n",
    "gen_Bif.loc[len(gen_Bif)] = ['Total', gen_Bif['Total Applications'].sum(), '']\n",
    "gen_Bif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cd980-4fff-4aeb-ba35-d3196692b855",
   "metadata": {},
   "source": [
    "# Centrewise Repeat Mobile numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a8851-9fc6-4b10-859d-89778d6ea8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_mobile = pd.pivot_table(data=unique_data, index=['District', 'Mobile'], values='Case Id', aggfunc='count').sort_values(by='Case Id', ascending=False).reset_index()\n",
    "repeat_mobile = repeat_mobile[repeat_mobile['Case Id']>30]\n",
    "repeat_mobile.loc[len(repeat_mobile)] = ['Grand Total','',repeat_mobile['Case Id'].sum()]\n",
    "repeat_mobile.rename(columns={\"Case Id\":\"Total Cases\"}, inplace=True)\n",
    "repeat_mobile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15061e1e-3ebf-4b8b-8878-fe552cfb73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.displot(data=unique_data, x='Age', kind='hist', bins=10, legend=True, kde=True, color='#F5A3C7', aspect=2)\n",
    "plot.set(ylabel='No. of citizens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f0f83-e371-4c71-bc6f-619e4f2b2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data of all duplicate records to Excel file.\n",
    "duplicateData.to_excel('C:\\\\Python\\\\export\\\\'+fn.split('.')[0]+'_duplicate.xlsx', index=False)\n",
    "print('Export to Excel Success! Total {0} duplicate records exported.'.format(duplicateData.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97034a24-50e0-4b42-a4f7-9a10ae102fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data of unique records to Excel file.\n",
    "with pd.ExcelWriter('C:\\\\Python\\\\export\\\\'+fn.split('.')[0]+'_uniques.xlsx') as writer:\n",
    "    unique_data.to_excel(writer, sheet_name='Schemes data', index=False)\n",
    "    projectwise_O_S_BR.to_excel(writer, sheet_name='projectwise_O_S_BR', index=False)\n",
    "    repeat_mobile.to_excel(writer,sheet_name='Repeat_mobile_nos', index=False)\n",
    "    Orgwise_Scheme_Diversity.to_excel(writer, sheet_name='Orgwise_Scheme_Diversity', index=False)\n",
    "    cit_sch_ratio.to_excel(writer, sheet_name='Citizen_Scheme_Ratio', index=False)\n",
    "    sch_doc_ratio.to_excel(writer, sheet_name='Scheme_Doc_Ratio', index=False)\n",
    "    top_bottom_hd.to_excel(writer, sheet_name='Top_Bottom_HD', index=False)\n",
    "    gen_Bif.to_excel(writer, sheet_name='Gender_Bifurcation', index=False)\n",
    "    if dfl.shape[0]<1:\n",
    "        dfl.to_excel(writer, sheet_name='DFL data', index=False)\n",
    "    \n",
    "print('Export to Excel Success! Total {0} unique records exported.'.format(unique_data.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

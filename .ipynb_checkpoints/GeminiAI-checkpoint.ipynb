{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9c36a-a3b5-46fd-9246-841bbf271893",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102c4109-217c-4869-9ef6-66b306610f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02297a9a-6be2-4e15-ba16-2ef2acb92c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key has imported!\n"
     ]
    }
   ],
   "source": [
    "f = open('C:\\Python\\geminiAPIKey.txt')\n",
    "key = f.read()\n",
    "genai.configure(api_key=key)\n",
    "print(\"API key has imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4774f5-87d4-46c5-8321-2275c5c88f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565116a5-ea8a-42f0-a2e3-ed2e02793997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In our solar system, Earth is a terrestrial planet, the third planet from the Sun, and the only known celestial body to support life.  It's relatively large compared to other inner planets, possessing a substantial iron core generating a protective magnetic field.  Its surface is predominantly covered by water, making oceans a defining feature.  Earth's atmosphere, composed primarily of nitrogen and oxygen, is crucial for sustaining life and moderating temperatures.  Finally, its orbit within the habitable zone allows for liquid water to exist on its surface.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name='gemini-1.5-flash')\n",
    "custom_config = genai.types.GenerationConfig(temperature=1.0)\n",
    "prompt = \"\"\"Generate some factual information to complete the following sentence in 5-6 lines:\n",
    "            In our solar system, Eath is a\"\"\"\n",
    "def genAIoutput(prompt, custom_config=custom_config):\n",
    "    response = model.generate_content(prompt,generation_config=custom_config)\n",
    "    display(Markdown(response.text))\n",
    "\n",
    "genAIoutput(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2b971-5026-4f16-8f5b-8bd0cc17eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"What is Machin Learning and also explain in details about supervised and unsupervised ML\"\"\"\n",
    "genAIoutput(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26921331-6eaf-4649-ae47-23e0473c4ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This error means your Langchain installation is outdated or corrupted. The `init_chat_model` function was removed or reorganized in a later version of Langchain.  You need to update Langchain to a version that's compatible with your code, or modify your code to use the new API.\n",
       "\n",
       "Here's how to troubleshoot and fix the problem:\n",
       "\n",
       "**1. Update Langchain:**\n",
       "\n",
       "The most likely solution is to update your LangChain package.  Open your command prompt or terminal and run:\n",
       "\n",
       "```bash\n",
       "pip install --upgrade langchain\n",
       "```\n",
       "\n",
       "or, if you use conda:\n",
       "\n",
       "```bash\n",
       "conda update -c conda-forge langchain\n",
       "```\n",
       "\n",
       "After the update, restart your Python interpreter or IDE.  This should resolve the issue if the problem was simply an outdated version.\n",
       "\n",
       "**2. Check your code:**\n",
       "\n",
       "If updating Langchain doesn't work, examine the code where you're using `init_chat_model`.  The function is no longer the standard way to initialize chat models in recent Langchain versions.  You likely need to instantiate a chat model directly using a class like `ChatOpenAI`, `ChatAnthropic`, or another specific model.\n",
       "\n",
       "For example, if you were previously using:\n",
       "\n",
       "```python\n",
       "from langchain.chat_models import init_chat_model\n",
       "\n",
       "chat = init_chat_model(\"gpt-3.5-turbo\") \n",
       "```\n",
       "\n",
       "You should replace it with something like this (assuming you're using OpenAI):\n",
       "\n",
       "```python\n",
       "from langchain.chat_models import ChatOpenAI\n",
       "\n",
       "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) \n",
       "```\n",
       "\n",
       "Remember to install the necessary OpenAI package:\n",
       "\n",
       "```bash\n",
       "pip install openai\n",
       "```\n",
       "\n",
       "And set your OpenAI API key as an environment variable (e.g., `OPENAI_API_KEY`).  Consult the Langchain documentation for the specific parameters and requirements of the chat model you're using.\n",
       "\n",
       "\n",
       "**3. Verify your installation:**\n",
       "\n",
       "* **Check your `pip` or `conda` environment:** Make sure you're using the correct Python environment where you installed Langchain.  Use `pip freeze` or `conda list` to see the installed packages.\n",
       "* **Reinstall Langchain:**  If you suspect a corrupted installation, try uninstalling and reinstalling Langchain:\n",
       "   ```bash\n",
       "   pip uninstall langchain\n",
       "   pip install langchain\n",
       "   ```\n",
       "* **Check for conflicting packages:**  Sometimes, conflicting packages can cause issues.  If you're still having trouble, try creating a new, clean virtual environment before installing Langchain.\n",
       "\n",
       "\n",
       "**4. Consult Langchain documentation:**\n",
       "\n",
       "The official Langchain documentation is your best resource. Check the release notes and API reference for the current version to see the correct way to initialize chat models.  Search for examples related to the specific chat model you're trying to use.\n",
       "\n",
       "\n",
       "If you've followed these steps and are still encountering the error, please provide the following information so I can assist you further:\n",
       "\n",
       "* **The exact code snippet** where the error occurs.\n",
       "* **The output of `pip freeze` or `conda list`** showing your installed packages.\n",
       "* **The version of Langchain** you're using (check with `pip show langchain` or `conda list langchain`).\n",
       "* **The specific chat model** you are trying to use.\n",
       "\n",
       "\n",
       "With more information, I can provide more tailored and accurate assistance.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"ImportError: cannot import name 'init_chat_model' from 'langchain.chat_models' (c:\\program files\\python311\\Lib\\site-packages\\langchain\\chat_models\\__init__.py)\"\n",
    "genAIoutput(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5d2de2-ad0c-42f4-a77e-157e179cf967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a90861-b359-4d7f-a9cf-6ce388797662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key has imported!\n"
     ]
    }
   ],
   "source": [
    "f = open('C:\\Python\\geminiAPIKey.txt')\n",
    "key = f.read()\n",
    "genai.configure(api_key=key)\n",
    "print(\"API key has imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04dfdb8a-ae05-4aeb-9ea5-a87792b22c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=1.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001FB142138D0>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(model=\"gemini-2.5-flash\", model_provider=\"google-genai\", api_key=key, temperature=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c209b7c-4902-4aa8-a144-f0b809001c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text to translate: Hi, My name is Akash! I'm here to learn Artificial Intellegence.\n",
      "Enter the translation language: Marathi\n"
     ]
    }
   ],
   "source": [
    "system_template = \"Translate the following text into {language}\"\n",
    "user_input = input(\"Enter the text to translate:\")\n",
    "language = input(\"Enter the translation language:\")\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": language, \"text\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758e434f-cd52-4cb3-b5f1-b2759239982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡§æ‡§ù‡•á ‡§®‡§æ‡§µ ‡§Ü‡§ï‡§æ‡§∂ ‡§Ü‡§π‡•á! ‡§Æ‡•Ä ‡§Ø‡•á‡§•‡•á ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§∂‡§ø‡§ï‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§≤‡•ã ‡§Ü‡§π‡•á."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af3272d-5f47-4422-9c03-f65cb0565ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ: \",display(Markdown(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea315d-6053-4f87-b1d8-9790acbb3fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: Hi, I'm  Akas Shahapure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ü§ñ : Hello Akas, it's a pleasure to meet you!\n",
       "\n",
       "I am here to assist you as a Virtual Assistant for Data Scientists. How can I help you with your data science needs today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: I want to use my org data which is on AWS SQL server and make a chat bot for the data we have using which user can ask questions like \"How many cases a employee has done against a specific project\". Please tell me step by step process to make a chat bot with the front end and backend code requirement\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ü§ñ : As a Data Scientist, I'm thrilled to help you design a solution for building a chatbot that interacts with your AWS SQL Server data! This is a fantastic application of Natural Language Processing and database integration.\n",
       "\n",
       "Creating a chatbot that can answer questions like \"How many cases an employee has done against a specific project\" involves several key components, from understanding natural language to executing SQL queries and presenting results.\n",
       "\n",
       "Here's a step-by-step process with front-end and back-end considerations:\n",
       "\n",
       "---\n",
       "\n",
       "### **Step-by-Step Process to Build a Data Chatbot for AWS SQL Server**\n",
       "\n",
       "#### **Phase 1: Data & Database Preparation (Data Scientist Focus)**\n",
       "\n",
       "**Step 1: Understand Your Data and Schema**\n",
       "Before writing any code, you need a deep understanding of your AWS SQL Server database schema.\n",
       "*   **Identify Key Tables:** Which tables hold information about employees, cases, projects, etc.?\n",
       "*   **Identify Key Columns:** What are the relevant columns in those tables (e.g., `employee_id`, `employee_name`, `project_id`, `project_name`, `case_id`, `case_status`, `case_date`)?\n",
       "*   **Understand Relationships:** How are these tables linked (e.g., `employees` to `cases` via `employee_id`, `projects` to `cases` via `project_id`)?\n",
       "*   **Sample Data:** Have sample data available for testing.\n",
       "\n",
       "    *Example Tables (Hypothetical):*\n",
       "    *   `Employees`: `employee_id (PK)`, `employee_name`, `department`\n",
       "    *   `Projects`: `project_id (PK)`, `project_name`, `start_date`, `end_date`\n",
       "    *   `Cases`: `case_id (PK)`, `employee_id (FK)`, `project_id (FK)`, `case_description`, `status`, `created_date`\n",
       "\n",
       "**Step 2: Database Connectivity & Security**\n",
       "You'll need a way for your back-end application to connect securely to your AWS SQL Server.\n",
       "*   **Credentials:** Store database credentials (hostname, port, database name, username, password) securely. AWS Secrets Manager is an excellent choice for this. Avoid hardcoding.\n",
       "*   **Network Access:** Ensure your back-end application (wherever it's hosted) has network access to your AWS SQL Server instance (e.g., through Security Groups, VPC peering).\n",
       "*   **Least Privilege:** Create a database user with only the necessary read-only permissions on the tables the chatbot needs to query.\n",
       "\n",
       "#### **Phase 2: Back-end Development (Data Scientist / Software Engineer Focus)**\n",
       "\n",
       "The back-end is the brain of your chatbot. It handles natural language understanding, SQL generation, database interaction, and response formatting.\n",
       "\n",
       "**Step 3: Natural Language to SQL (NL2SQL) Engine**\n",
       "This is the most critical and complex part. You need to convert a user's natural language question into an executable SQL query.\n",
       "\n",
       "*   **Approach A: Rule-Based / Template-Based (Simpler, Less Flexible)**\n",
       "    *   **Intent Recognition:** Identify the user's intent (e.g., \"count cases,\" \"find projects,\" \"get employee details\"). You can use libraries like `spaCy` or `NLTK` for keyword extraction or simple rule matching.\n",
       "    *   **Entity Extraction:** Extract specific entities like `employee name`, `project name`, `date ranges`, `status` from the user's query.\n",
       "    *   **SQL Template Mapping:** Map recognized intents and entities to predefined SQL query templates.\n",
       "        *   *Example:* If intent is \"count cases\" and entities are `employee_name=\"John Doe\"` and `project_name=\"Alpha\"`, construct a query like:\n",
       "            ```sql\n",
       "            SELECT COUNT(C.case_id)\n",
       "            FROM Cases C\n",
       "            JOIN Employees E ON C.employee_id = E.employee_id\n",
       "            JOIN Projects P ON C.project_id = P.project_id\n",
       "            WHERE E.employee_name = 'John Doe' AND P.project_name = 'Alpha';\n",
       "            ```\n",
       "    *   **Pros:** Full control, less dependency on external APIs, good for limited, well-defined questions.\n",
       "    *   **Cons:** Hard to scale, new question types require code changes, not truly \"natural language.\"\n",
       "\n",
       "*   **Approach B: Large Language Models (LLMs) - Recommended for Flexibility**\n",
       "    *   Leverage powerful pre-trained LLMs (e.g., OpenAI's GPT models, Google's Gemini, Hugging Face models like Code Llama) to generate SQL.\n",
       "    *   **Prompt Engineering:** The key is to provide the LLM with:\n",
       "        1.  **Database Schema:** Explain your table names, column names, data types, and relationships.\n",
       "        2.  **User Question:** The natural language query.\n",
       "        3.  **Instructions:** Tell the LLM to generate a valid SQL Server query based on the schema and question.\n",
       "        4.  **Examples (Few-Shot Learning):** Provide a few examples of NL questions and their corresponding SQL queries to guide the LLM.\n",
       "    *   **Pros:** Highly flexible, can handle variations in language, understands context better, scales to new question types without extensive re-coding.\n",
       "    *   **Cons:** API costs (if using external models), potential for hallucination (generating incorrect SQL), security concerns (ensure generated SQL is safe before execution), performance can vary.\n",
       "\n",
       "**Step 4: Database Interaction Layer**\n",
       "This component executes the generated SQL and fetches results.\n",
       "*   **Python Library:** Use `pyodbc` for connecting to SQL Server.\n",
       "*   **Execution:**\n",
       "    *   Receive the SQL query from the NL2SQL engine.\n",
       "    *   **Crucial Security Step: SQL Injection Prevention:** If you're not using a full-fledged ORM and relying on raw SQL generated by an LLM, you *must* validate the generated SQL or ensure the LLM is constrained not to generate malicious queries (e.g., `DROP TABLE`). A common practice is to only allow `SELECT` statements and filter out any `INSERT`, `UPDATE`, `DELETE`, `DROP`, etc.\n",
       "    *   Execute the query and fetch results.\n",
       "*   **Error Handling:** Gracefully handle cases like:\n",
       "    *   Invalid SQL generated by the NL2SQL engine.\n",
       "    *   Database connection errors.\n",
       "    *   No data found for the query.\n",
       "\n",
       "**Step 5: Response Generation**\n",
       "Convert the SQL query results into a user-friendly natural language response.\n",
       "*   **Simple:** \"John Doe has completed 5 cases for the Alpha project.\"\n",
       "*   **Complex:** If results are a table, present them clearly.\n",
       "*   **LLMs for Response:** You can even use an LLM to summarize complex query results into a coherent natural language answer.\n",
       "\n",
       "**Step 6: Back-end API Framework (e.g., Flask, FastAPI)**\n",
       "This is where your chatbot logic lives and exposes an endpoint for the front-end.\n",
       "\n",
       "*   **API Endpoint:** A POST endpoint (e.g., `/chat`) that accepts the user's question.\n",
       "*   **Workflow:**\n",
       "    1.  Receive user question via HTTP POST request.\n",
       "    2.  Pass question to NL2SQL engine.\n",
       "    3.  Receive generated SQL.\n",
       "    4.  Execute SQL against AWS SQL Server.\n",
       "    5.  Process results and generate a natural language response.\n",
       "    6.  Return the response in JSON format.\n",
       "\n",
       "---\n",
       "\n",
       "**Back-end Code Requirements (Python Example using Flask & pyodbc)**\n",
       "\n",
       "**1. `requirements.txt`**\n",
       "```\n",
       "Flask\n",
       "pyodbc\n",
       "openai # if using OpenAI's LLMs\n",
       "```\n",
       "\n",
       "**2. `app.py` (Simplified Example)**\n",
       "\n",
       "```python\n",
       "from flask import Flask, request, jsonify\n",
       "import pyodbc\n",
       "import os\n",
       "import openai # Example if using OpenAI for NL2SQL\n",
       "\n",
       "app = Flask(__name__)\n",
       "\n",
       "# --- Configuration (Store securely, e.g., environment variables or AWS Secrets Manager) ---\n",
       "DB_SERVER = os.environ.get(\"DB_SERVER\", \"your_aws_sql_server.amazonaws.com\")\n",
       "DB_DATABASE = os.environ.get(\"DB_DATABASE\", \"YourOrgDB\")\n",
       "DB_USERNAME = os.environ.get(\"DB_USERNAME\", \"db_user_chatbot\")\n",
       "DB_PASSWORD = os.environ.get(\"DB_PASSWORD\", \"your_secure_password\")\n",
       "DB_DRIVER = '{ODBC Driver 17 for SQL Server}' # Ensure this driver is installed on your server/container\n",
       "\n",
       "# OpenAI API Key (if using OpenAI LLMs)\n",
       "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
       "openai.api_key = OPENAI_API_KEY\n",
       "\n",
       "# --- Database Schema Context for LLM (Very Important!) ---\n",
       "# This schema description will be part of your prompt to the LLM\n",
       "DATABASE_SCHEMA = \"\"\"\n",
       "Tables:\n",
       "- Employees (employee_id INT PRIMARY KEY, employee_name VARCHAR(255), department VARCHAR(255))\n",
       "- Projects (project_id INT PRIMARY KEY, project_name VARCHAR(255), start_date DATE, end_date DATE)\n",
       "- Cases (case_id INT PRIMARY KEY, employee_id INT FOREIGN KEY REFERENCES Employees(employee_id), project_id INT FOREIGN KEY REFERENCES Projects(project_id), case_description TEXT, status VARCHAR(50), created_date DATETIME)\n",
       "\n",
       "Relationships:\n",
       "- Cases.employee_id -> Employees.employee_id\n",
       "- Cases.project_id -> Projects.project_id\n",
       "\"\"\"\n",
       "\n",
       "def get_db_connection():\n",
       "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
       "    conn_str = (\n",
       "        f\"DRIVER={DB_DRIVER};SERVER={DB_SERVER};DATABASE={DB_DATABASE};\"\n",
       "        f\"UID={DB_USERNAME};PWD={DB_PASSWORD}\"\n",
       "    )\n",
       "    try:\n",
       "        conn = pyodbc.connect(conn_str)\n",
       "        return conn\n",
       "    except pyodbc.Error as ex:\n",
       "        sqlstate = ex.args[0]\n",
       "        app.logger.error(f\"Database connection error: {sqlstate} - {ex}\")\n",
       "        return None\n",
       "\n",
       "def nl_to_sql_llm(user_question):\n",
       "    \"\"\"\n",
       "    Converts natural language question to SQL using an LLM.\n",
       "    This is a conceptual example, actual prompt engineering will vary.\n",
       "    \"\"\"\n",
       "    if not OPENAI_API_KEY:\n",
       "        return \"Error: OpenAI API key not configured.\"\n",
       "\n",
       "    prompt = (\n",
       "        f\"You are a SQL Server expert. Given the following database schema, \"\n",
       "        f\"generate a SQL query that answers the user's question. \"\n",
       "        f\"Only generate SELECT statements. Do NOT generate INSERT, UPDATE, DELETE, or DROP statements.\\n\\n\"\n",
       "        f\"Schema:\\n{DATABASE_SCHEMA}\\n\\n\"\n",
       "        f\"User Question: {user_question}\\n\\n\"\n",
       "        f\"SQL Query:\"\n",
       "    )\n",
       "\n",
       "    try:\n",
       "        response = openai.Completion.create(\n",
       "            engine=\"text-davinci-003\", # Or gpt-3.5-turbo, gpt-4 for ChatCompletion\n",
       "            prompt=prompt,\n",
       "            max_tokens=200,\n",
       "            n=1,\n",
       "            stop=[\"\\n\\n\", \";\"], # Stop generation at the end of a query\n",
       "            temperature=0.0 # Make it deterministic\n",
       "        )\n",
       "        sql_query = response.choices[0].text.strip()\n",
       "\n",
       "        # Basic validation: Ensure it's a SELECT query and not malicious\n",
       "        if not sql_query.upper().startswith(\"SELECT\"):\n",
       "            app.logger.warning(f\"Generated non-SELECT query: {sql_query}\")\n",
       "            return None # Or raise an error\n",
       "        \n",
       "        # Example to use ChatCompletion API if you prefer gpt-3.5-turbo/gpt-4\n",
       "        # messages = [\n",
       "        #     {\"role\": \"system\", \"content\": \"You are a SQL Server expert. Generate SELECT queries based on schema.\"},\n",
       "        #     {\"role\": \"user\", \"content\": f\"Schema:\\n{DATABASE_SCHEMA}\\n\\nUser Question: {user_question}\\n\\nSQL Query:\"}\n",
       "        # ]\n",
       "        # chat_response = openai.ChatCompletion.create(\n",
       "        #     model=\"gpt-3.5-turbo\",\n",
       "        #     messages=messages,\n",
       "        #     temperature=0.0\n",
       "        # )\n",
       "        # sql_query = chat_response.choices[0].message['content'].strip()\n",
       "\n",
       "\n",
       "        return sql_query\n",
       "    except openai.error.OpenAIError as e:\n",
       "        app.logger.error(f\"OpenAI API error: {e}\")\n",
       "        return None\n",
       "    except Exception as e:\n",
       "        app.logger.error(f\"Error in NL to SQL conversion: {e}\")\n",
       "        return None\n",
       "\n",
       "\n",
       "@app.route('/chat', methods=['POST'])\n",
       "def chat():\n",
       "    user_message = request.json.get('message')\n",
       "    if not user_message:\n",
       "        return jsonify({\"response\": \"Please provide a message.\"}), 400\n",
       "\n",
       "    sql_query = nl_to_sql_llm(user_message)\n",
       "\n",
       "    if not sql_query:\n",
       "        return jsonify({\"response\": \"I couldn't generate a valid SQL query from your request. Please try rephrasing.\"}), 500\n",
       "\n",
       "    conn = get_db_connection()\n",
       "    if not conn:\n",
       "        return jsonify({\"response\": \"I'm having trouble connecting to the database right now. Please try again later.\"}), 500\n",
       "\n",
       "    try:\n",
       "        cursor = conn.cursor()\n",
       "        cursor.execute(sql_query)\n",
       "        columns = [column[0] for column in cursor.description]\n",
       "        rows = cursor.fetchall()\n",
       "\n",
       "        if not rows:\n",
       "            response_message = \"I couldn't find any data matching your request.\"\n",
       "        else:\n",
       "            # Simple response generation - you can make this more sophisticated\n",
       "            # For \"How many cases...\", it should return a single count\n",
       "            if \"COUNT(\" in sql_query.upper() and len(rows) == 1 and len(columns) == 1:\n",
       "                response_message = f\"The answer is: {rows[0][0]}\"\n",
       "            else:\n",
       "                # For more complex queries, you might want to format as a table or summary\n",
       "                # For this example, let's just return the first few rows as a string\n",
       "                results_str = \"\"\n",
       "                for i, row in enumerate(rows):\n",
       "                    if i < 3: # Show max 3 rows for brevity\n",
       "                        results_str += \", \".join([f\"{col}: {val}\" for col, val in zip(columns, row)]) + \"\\n\"\n",
       "                if len(rows) > 3:\n",
       "                    results_str += f\"... and {len(rows) - 3} more results.\"\n",
       "                response_message = f\"Here are some results:\\n{results_str}\"\n",
       "\n",
       "        return jsonify({\"response\": response_message})\n",
       "\n",
       "    except pyodbc.ProgrammingError as e:\n",
       "        app.logger.error(f\"SQL execution error: {e}. Query: {sql_query}\")\n",
       "        return jsonify({\"response\": f\"I encountered an error trying to run the query: {e}. Please check the question or the generated SQL if you have access.\"}), 400\n",
       "    except Exception as e:\n",
       "        app.logger.error(f\"An unexpected error occurred: {e}\")\n",
       "        return jsonify({\"response\": \"An unexpected error occurred. Please try again or contact support.\"}), 500\n",
       "    finally:\n",
       "        if conn:\n",
       "            conn.close()\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    # For local development, install 'python-dotenv' and create a .env file\n",
       "    # For production, use actual environment variables or secrets manager\n",
       "    # from dotenv import load_dotenv\n",
       "    # load_dotenv()\n",
       "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
       "\n",
       "```\n",
       "\n",
       "#### **Phase 3: Front-end Development**\n",
       "\n",
       "The front-end provides the user interface for interacting with the chatbot.\n",
       "\n",
       "**Step 7: Front-end UI (HTML, CSS, JavaScript)**\n",
       "A simple chat interface will suffice.\n",
       "\n",
       "*   **HTML Structure:**\n",
       "    *   A container for chat messages.\n",
       "    *   An input field for the user's message.\n",
       "    *   A send button.\n",
       "*   **CSS Styling:** Make it look presentable.\n",
       "*   **JavaScript Logic:**\n",
       "    *   Capture user input.\n",
       "    *   Send the user's message to your back-end API (`/chat` endpoint) using `fetch` or `XMLHttpRequest`.\n",
       "    *   Display the user's message and the chatbot's response in the chat history.\n",
       "\n",
       "---\n",
       "\n",
       "**Front-end Code Requirements (Basic HTML, CSS, JavaScript Example)**\n",
       "\n",
       "**1. `index.html`**\n",
       "\n",
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Org Data Chatbot</title>\n",
       "    <style>\n",
       "        body { font-family: sans-serif; margin: 0; padding: 20px; background-color: #f4f7f6; }\n",
       "        #chat-container {\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background: #fff;\n",
       "            border-radius: 8px;\n",
       "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            height: 70vh; /* Adjust height as needed */\n",
       "        }\n",
       "        #chat-history {\n",
       "            flex-grow: 1;\n",
       "            padding: 20px;\n",
       "            overflow-y: auto;\n",
       "            border-bottom: 1px solid #eee;\n",
       "        }\n",
       "        .message {\n",
       "            margin-bottom: 10px;\n",
       "            padding: 8px 12px;\n",
       "            border-radius: 15px;\n",
       "            max-width: 70%;\n",
       "            word-wrap: break-word;\n",
       "        }\n",
       "        .user-message {\n",
       "            background-color: #007bff;\n",
       "            color: white;\n",
       "            align-self: flex-end;\n",
       "            margin-left: auto;\n",
       "        }\n",
       "        .bot-message {\n",
       "            background-color: #e2e6ea;\n",
       "            color: #333;\n",
       "            align-self: flex-start;\n",
       "            margin-right: auto;\n",
       "        }\n",
       "        #chat-input-area {\n",
       "            display: flex;\n",
       "            padding: 15px;\n",
       "            background-color: #f9f9f9;\n",
       "            border-top: 1px solid #eee;\n",
       "        }\n",
       "        #user-input {\n",
       "            flex-grow: 1;\n",
       "            padding: 10px;\n",
       "            border: 1px solid #ddd;\n",
       "            border-radius: 20px;\n",
       "            margin-right: 10px;\n",
       "            font-size: 16px;\n",
       "        }\n",
       "        #send-button {\n",
       "            background-color: #28a745;\n",
       "            color: white;\n",
       "            border: none;\n",
       "            padding: 10px 20px;\n",
       "            border-radius: 20px;\n",
       "            cursor: pointer;\n",
       "            font-size: 16px;\n",
       "            transition: background-color 0.2s;\n",
       "        }\n",
       "        #send-button:hover {\n",
       "            background-color: #218838;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <div id=\"chat-container\">\n",
       "        <div id=\"chat-history\">\n",
       "            <div class=\"message bot-message\">Hello! I'm your Org Data Chatbot. Ask me anything about our data!</div>\n",
       "        </div>\n",
       "        <div id=\"chat-input-area\">\n",
       "            <input type=\"text\" id=\"user-input\" placeholder=\"Type your question...\">\n",
       "            <button id=\"send-button\">Send</button>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "        const chatHistory = document.getElementById('chat-history');\n",
       "        const userInput = document.getElementById('user-input');\n",
       "        const sendButton = document.getElementById('send-button');\n",
       "\n",
       "        const BACKEND_URL = 'http://127.0.0.1:5000/chat'; // Change this to your deployed backend URL\n",
       "\n",
       "        sendButton.addEventListener('click', sendMessage);\n",
       "        userInput.addEventListener('keypress', function(e) {\n",
       "            if (e.key === 'Enter') {\n",
       "                sendMessage();\n",
       "            }\n",
       "        });\n",
       "\n",
       "        function addMessage(text, sender) {\n",
       "            const messageDiv = document.createElement('div');\n",
       "            messageDiv.classList.add('message');\n",
       "            messageDiv.classList.add(sender === 'user' ? 'user-message' : 'bot-message');\n",
       "            messageDiv.innerText = text;\n",
       "            chatHistory.appendChild(messageDiv);\n",
       "            chatHistory.scrollTop = chatHistory.scrollHeight; // Scroll to bottom\n",
       "        }\n",
       "\n",
       "        async function sendMessage() {\n",
       "            const message = userInput.value.trim();\n",
       "            if (message === '') return;\n",
       "\n",
       "            addMessage(message, 'user');\n",
       "            userInput.value = '';\n",
       "\n",
       "            try {\n",
       "                const response = await fetch(BACKEND_URL, {\n",
       "                    method: 'POST',\n",
       "                    headers: {\n",
       "                        'Content-Type': 'application/json',\n",
       "                    },\n",
       "                    body: JSON.stringify({ message: message })\n",
       "                });\n",
       "\n",
       "                if (!response.ok) {\n",
       "                    throw new Error(`HTTP error! status: ${response.status}`);\n",
       "                }\n",
       "\n",
       "                const data = await response.json();\n",
       "                addMessage(data.response, 'bot');\n",
       "\n",
       "            } catch (error) {\n",
       "                console.error('Error sending message:', error);\n",
       "                addMessage(\"Oops! Something went wrong. Please try again.\", 'bot');\n",
       "            }\n",
       "        }\n",
       "    </script>\n",
       "</body>\n",
       "</html>\n",
       "```\n",
       "\n",
       "#### **Phase 4: Deployment & Maintenance**\n",
       "\n",
       "**Step 8: Deployment**\n",
       "*   **Back-end:** Deploy your Flask/FastAPI application.\n",
       "    *   **AWS EC2:** Run it on a virtual machine.\n",
       "    *   **AWS Lambda + API Gateway:** Serverless approach, cost-effective for intermittent use.\n",
       "    *   **AWS ECS/EKS:** Containerized deployment for scalability.\n",
       "*   **Front-end:** Host your `index.html`, CSS, and JS files.\n",
       "    *   **AWS S3 (Static Website Hosting):** Simplest and cheapest for static files.\n",
       "    *   **AWS Amplify:** For more sophisticated front-end frameworks.\n",
       "\n",
       "**Step 9: Monitoring & Maintenance**\n",
       "*   **Logging:** Monitor your back-end logs for errors (SQL generation issues, DB connectivity, etc.).\n",
       "*   **Performance:** Monitor query execution times.\n",
       "*   **User Feedback:** Gather feedback to improve NL2SQL accuracy.\n",
       "*   **Schema Changes:** If your database schema changes, you'll need to update your `DATABASE_SCHEMA` context for the LLM and potentially retrain/re-prompt your NL2SQL engine.\n",
       "*   **Security Audits:** Regularly review security practices, especially regarding database access and generated SQL.\n",
       "\n",
       "---\n",
       "\n",
       "### **Key Data Science Considerations:**\n",
       "\n",
       "*   **Prompt Engineering:** For LLM-based NL2SQL, the quality of your prompt is paramount. Experiment with clear instructions, examples, and constraints.\n",
       "*   **Guardrails:** Implement strict guardrails around LLM-generated SQL to prevent harmful queries (e.g., only `SELECT` statements, no `DROP`, `DELETE`, etc.).\n",
       "*   **Ambiguity Handling:** What if a question is ambiguous? Your bot should ideally ask clarifying questions. (This adds complexity to NL2SQL).\n",
       "*   **Data Masking/Anonymization:** If your data contains sensitive information, consider data masking before returning results, or limit the chatbot's access to only non-sensitive subsets.\n",
       "*   **Performance Tuning:** Complex natural language queries can translate into complex SQL. Ensure your database is indexed appropriately for common query patterns.\n",
       "\n",
       "This detailed roadmap should give you a solid foundation to start building your AWS SQL Server data chatbot! Good luck!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"Act as a virtual assistance of Data Scientist and this will be your primary role but if user asks any questions out of the context then politely deny to answer\n",
    "                    but ask if user want to change your role to answer the question related to specific domain and if user confirms then change your role to \n",
    "                    the specific domain and after answering change your role back to Data Scientist.\"\"\"\n",
    "\n",
    "def chat_bot(user_input):\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\",system_template),(\"user\",\"{text}\")])\n",
    "    prompt = prompt_template.invoke({\"text\":user_input})\n",
    "    response = model.invoke(prompt)\n",
    "    display(Markdown(\"ü§ñ : \"+response.content))\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User:\")\n",
    "    print(\"\\n\")\n",
    "    if user_input.lower() in ['bye','exit','finish','end']:\n",
    "        break\n",
    "    chat_bot(user_input)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

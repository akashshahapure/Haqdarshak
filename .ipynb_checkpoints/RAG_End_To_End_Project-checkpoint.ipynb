{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RDWeFTh8-3il"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain\n",
        "#!pip install langchain-openai\n",
        "#!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain-chroma"
      ],
      "metadata": {
        "id": "mCvUpD3M_HjT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter OpenAI API key\n",
        "from getpass import getpass\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key here: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1nImaB__Hm7",
        "outputId": "460acef8-de45-42ee-8414-45a2e5118690"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key here: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Environment Variables\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "pxVlHxok_HqB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Embedding Model\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "openai_embed_model = OpenAIEmbeddings(model =\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "SW1qsG-6_HtJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI Generating Model\n",
        "from langchain_openai import ChatOpenAI\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "DXQ8CeD3_HwD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and Processing the data\n",
        "\n",
        "#### if you can't download using the following code\n",
        "#### go to https://drive.google.com/file/d/1aZxZejfteVuofISodUrY2CDoyuPLYDGZ download it\n",
        "#### manually upload it on colab\n",
        "!gdown 1aZxZejfteVuofISodUrY2CDoyuPLYDGZ"
      ],
      "metadata": {
        "id": "O0YAzJrBEpqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1aZxZejfteVuofISodUrY2CDoyuPLYDGZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lxxwd1T_Hza",
        "outputId": "564698f1-3964-4338-aa73-106ec4c08b61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aZxZejfteVuofISodUrY2CDoyuPLYDGZ\n",
            "To: /content/rag_docs.zip\n",
            "\r  0% 0.00/5.92M [00:00<?, ?B/s]\r100% 5.92M/5.92M [00:00<00:00, 78.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/rag_docs.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-_b0ugCE1d3",
        "outputId": "f013cf19-2510-4a19-d40e-fba618fdaa25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/rag_docs.zip\n",
            "   creating: rag_docs/\n",
            "  inflating: rag_docs/attention_paper.pdf  \n",
            "  inflating: rag_docs/cnn_paper.pdf  \n",
            "  inflating: rag_docs/resnet_paper.pdf  \n",
            "  inflating: rag_docs/vision_transformer.pdf  \n",
            "  inflating: rag_docs/wikidata_rag_demo.jsonl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install jq\n",
        "#!pip install pymupdf"
      ],
      "metadata": {
        "id": "WXciFrWTKQ7I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Process JSON Documents(wikidata)"
      ],
      "metadata": {
        "id": "ut5uVQSlJMhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import JSONLoader\n",
        "\n",
        "loader = JSONLoader(file_path='/content/rag_docs/wikidata_rag_demo.jsonl',\n",
        "                    jq_schema=\".\", text_content=False,\n",
        "                   json_lines=True )\n",
        "\n",
        "wiki_docs = loader.load()\n",
        "print(len(wiki_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpJT8LCCE1hW",
        "outputId": "082fa69d-84fc-4528-c193-ddf02b0ef991"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu4NANcwKIlf",
        "outputId": "448e6e97-57cb-4fe9-a9e5-6a8c6bc5654d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/rag_docs/wikidata_rag_demo.jsonl', 'seq_num': 4}, page_content='{\"id\": \"71548\", \"title\": \"Chi-square distribution\", \"paragraphs\": [\"In probability theory and statistics, the chi-square distribution (also chi-squared or formula_1\\\\u00a0 distribution) is one of the most widely used theoretical probability distributions. Chi-square distribution with formula_2 degrees of freedom is written as formula_3. It is a special case of gamma distribution.\", \"Chi-square distribution is primarily used in statistical significance tests and confidence intervals. It is useful, because it is relatively easy to show that certain probability distributions come close to it, under certain conditions. One of these conditions is that the null hypothesis must be true. Another one is that the different random variables (or observations) must be independent of each other.\"]}')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs[300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrOz15oXL2JF",
        "outputId": "e1afd94a-c008-44b6-951c-b03d55601528"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/rag_docs/wikidata_rag_demo.jsonl', 'seq_num': 301}, page_content='{\"id\": \"34097\", \"title\": \"Florence Nightingale\", \"paragraphs\": [\"Florence Nightingale, OM (12 May 1820 \\\\u2013 13 August 1910), was an English nurse. She helped create the modern techniques of nursing. She became a leader of the team of nurses who helped wounded soldiers during the Crimean War.\", \"She was the first female to receive the Order of Merit, one of the highest honours awarded by the British monarch. As a nurse she was given the name \\'The Lady with the Lamp\\' because at night, she checked on the wounded soldiers and always carried \\'The Lamp\\' with her. Florence Nightingale was a wonderful woman who fought the odds of not living a life expected by her family. She helped make modern nursing possible. Nightingale was a prodigious and versatile writer, and lived to be 90 years old.\", \"In her lifetime she was concerned with spreading medical knowledge. Some of her books were written in simple English so that they could easily be understood by those with poor reading skills. She also was an early user of graphs and diagrams to display data.\"]}')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs[1300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLYCVsNGE1kh",
        "outputId": "685337b2-f7d9-4b70-fbd5-e451da98a6b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/rag_docs/wikidata_rag_demo.jsonl', 'seq_num': 1301}, page_content='{\"id\": \"471921\", \"title\": \"CamelCase\", \"paragraphs\": [\"CamelCase (camel case, camel caps or medial capitals) is the practice of writing compound words or phrases so that each next word or abbreviation begins with a capital letter. CamelCase usually starts with a capital. When used in a programming language, it usually starts with a lowercase letter. Common examples are PowerPoint or iPhone.\", \"There are many variations of CamelCase. A few important ones are:\", \"The first use of medial capitals was the notation for chemical formulae invented by the Swedish chemist Berzelius in 1813. He did this to replace the large amount of naming and symbol systems used by chemists at that time. He suggested to show each chemical element by a symbol of one or two letters, the first one being capitalized. The capitalization allowed formulae like \\'NaCl\\' to be written without spaces and still be read without confusion. This system is still in use today.\"]}')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain.docstore.document import Document\n",
        "wiki_docs_processed = []\n",
        "for doc in wiki_docs:\n",
        "  doc = json.loads(doc.page_content)\n",
        "  metadata = {\n",
        "              \"title\":doc['title'],\n",
        "              \"id\": doc['id'],\n",
        "              \"source\": 'Wikipedia'}\n",
        "  data = ' '.join(doc['paragraphs'])\n",
        "  wiki_docs_processed.append(Document(page_content=data, metadata=metadata))"
      ],
      "metadata": {
        "id": "eglhekaqE1oC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_docs_processed[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdBH4Gu5MHIH",
        "outputId": "70b601b4-dd2b-463a-de0c-a764232141d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'title': 'Dattatreya', 'id': '86394', 'source': 'Wikipedia'}, page_content='Dattatreya is the God who is an incarnation of the Divine Trinity Brahma, Vishnu and Siva. The word Datta means \"Given\", Datta is called so because the divine trinity have \"given\" themselves in the form of a son to the sage couple Guru Atri and Mata Anusuya. He is the son of Guru Atri, hence the name \"Atreya.\" In the Nath tradition, Dattatreya is seen as an Avatar or incarnation of the Lord Shiva and as the Adi-Guru (First Teacher) of the Adi-Nath sampradaya of the Nathas. Although Dattatreya was at first a \"Lord of Yoga\" with Tantric traits, he was adapted and assimilated into the more devotional cults; while still worshiped by millions of Hindus, he is approached more as a benevolent God than as a teacher of the highest essence of Indian thought. Though the Dattatreya of the Natha tradition coexisted and intermingled with the Puranic, Brahmanical tradition of the Datta sampradaya, here we shall focus almost exclusively on the earlier Tantric manifestation of Datta. Shri Gurudev Mahendranath had no doubt that Dattatreya was an historical figure. He stated that Datta was born on Wednesday, the fourteenth day of the full moon in the month of Margasirsa, though he does not mention the year.')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and processing pdf file"
      ],
      "metadata": {
        "id": "-hFE9zTZQsig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def create_simple_chunks(file_path, chunk_size=3000, chunk_overlap=300):\n",
        "  print(\"Loading pages: \", file_path)\n",
        "  loader = PyMuPDFLoader(file_path)\n",
        "  doc_pages = loader.load()\n",
        "\n",
        "  print(\"Chunking pages :\", file_path)\n",
        "  splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  doc_chunks = splitter.split_documents(doc_pages)\n",
        "\n",
        "  print(\"Finished Processing :\", file_path)\n",
        "  print()\n",
        "  return doc_chunks"
      ],
      "metadata": {
        "id": "_xeMWxbuMHMF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "pdf_files = glob(\"/content/rag_docs/*.pdf\")\n",
        "pdf_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAidcERrMHPU",
        "outputId": "7594215b-acad-46ca-9e7a-50368e115dee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/rag_docs/attention_paper.pdf',\n",
              " '/content/rag_docs/vision_transformer.pdf',\n",
              " '/content/rag_docs/resnet_paper.pdf',\n",
              " '/content/rag_docs/cnn_paper.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs = []\n",
        "\n",
        "for fp in pdf_files:\n",
        "  paper_docs.extend(create_simple_chunks(file_path=fp, chunk_size=3000, chunk_overlap=300))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERCJPA81MHSb",
        "outputId": "9f21603e-8864-4e98-db39-4e8b000687f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pages:  /content/rag_docs/attention_paper.pdf\n",
            "Chunking pages : /content/rag_docs/attention_paper.pdf\n",
            "Finished Processing : /content/rag_docs/attention_paper.pdf\n",
            "\n",
            "Loading pages:  /content/rag_docs/vision_transformer.pdf\n",
            "Chunking pages : /content/rag_docs/vision_transformer.pdf\n",
            "Finished Processing : /content/rag_docs/vision_transformer.pdf\n",
            "\n",
            "Loading pages:  /content/rag_docs/resnet_paper.pdf\n",
            "Chunking pages : /content/rag_docs/resnet_paper.pdf\n",
            "Finished Processing : /content/rag_docs/resnet_paper.pdf\n",
            "\n",
            "Loading pages:  /content/rag_docs/cnn_paper.pdf\n",
            "Chunking pages : /content/rag_docs/cnn_paper.pdf\n",
            "Finished Processing : /content/rag_docs/cnn_paper.pdf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(paper_docs))\n",
        "print(len(wiki_docs_processed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIOFKOMbMHVq",
        "outputId": "efc6da00-5000-4b12-b113-6c98a7354e6e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93\n",
            "1801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8RS-vwYTTYt",
        "outputId": "1d78abdc-b0f0-4b26-e1f4-d5de2e3939de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-08-03T00:07:29+00:00', 'source': '/content/rag_docs/attention_paper.pdf', 'file_path': '/content/rag_docs/attention_paper.pdf', 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-08-03T00:07:29+00:00', 'trapped': '', 'modDate': 'D:20230803000729Z', 'creationDate': 'D:20230803000729Z', 'page': 1}, page_content='described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper_docs[40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku6SfpBhTTdD",
        "outputId": "97ee5689-1208-4707-df95-b115ed9cb84f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-06-04T00:19:58+00:00', 'source': '/content/rag_docs/vision_transformer.pdf', 'file_path': '/content/rag_docs/vision_transformer.pdf', 'total_pages': 22, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-06-04T00:19:58+00:00', 'trapped': '', 'modDate': 'D:20210604001958Z', 'creationDate': 'D:20210604001958Z', 'page': 9}, page_content='In ICCV, 2019.\\nZilong Huang, Xinggang Wang, Yunchao Wei, Lichao Huang, Humphrey Shi, Wenyu Liu, and\\nThomas S. Huang. Ccnet: Criss-cross attention for semantic segmentation. In ICCV, 2020.\\nOlivier J. H´enaff, Aravind Srinivas, Jeffrey De Fauw, Ali Razavi, Carl Doersch, S. M. Ali Eslami,\\nand Aaron van den Oord. Data-efﬁcient image recognition with contrastive predictive coding. In\\nICML, 2020.\\n10')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine all documents in one list for embedding and storing into vector database"
      ],
      "metadata": {
        "id": "IpHa9cyzT09K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_docs = wiki_docs_processed + paper_docs\n",
        "print(len(total_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7JKBSPoTTgS",
        "outputId": "09fe608f-91db-43f2-c06c-f8425098ebb5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chromadb with embedding\n",
        "from langchain_chroma import Chroma\n",
        "# please execute only once if you are using your local machine or even using colab\n",
        "chroma_db = Chroma.from_documents(documents=total_docs,\n",
        "                                  collection_name=\"my_db\",\n",
        "                                  embedding = openai_embed_model,\n",
        "                                  collection_metadata = {\"hnsw:space\":\"cosine\"},\n",
        "                                  persist_directory=\"/content/my_chromadb\")"
      ],
      "metadata": {
        "id": "RTQ6mXPFTTjd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Vector DB from disk\n",
        "\n",
        "chroma_db = Chroma(persist_directory=\"/content/my_chromadb\",\n",
        "                   embedding_function=openai_embed_model,\n",
        "                   collection_name=\"my_db\")\n",
        "chroma_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f4X07VSTTmo",
        "outputId": "78b3fbe6-6981-48b2-ba66-63f82d94d2e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7a54556fd310>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Similarity based Retrieval"
      ],
      "metadata": {
        "id": "fqF68Py8V9Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})"
      ],
      "metadata": {
        "id": "rR4hWFHGVgGB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "def display_docs(docs):\n",
        "  for doc in docs:\n",
        "    print(\"Metadata :\", doc.metadata)\n",
        "    display(Markdown(doc.page_content[:1000]))\n",
        "    print()"
      ],
      "metadata": {
        "id": "wZqd_GsoVgJm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"What is Machine Learning?\"\n",
        "top_docs = similarity_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "tj-jpttYWTiY",
        "outputId": "6290b4b2-3e8e-468b-d9ea-f1c56110caba"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata : {'title': 'Machine learning', 'id': '564928', 'source': 'Wikipedia'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'source': 'Wikipedia', 'id': '359370', 'title': 'Supervised learning'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'id': '663523', 'title': 'Deep learning', 'source': 'Wikipedia'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, images or handwriting, is easy to do for humans. However, for a computer, these tasks are very difficult to do. In a multi-layer neural network (having more than two layers), the information processed will become more abstract with each added layer. Deep learning models are inspired by information processing and communication patterns in biological nervous systems; they are different from the structural and functional properties of biological brains (especially the human brain) in many ways, whic"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'title': 'Artificial intelligence', 'source': 'Wikipedia', 'id': '6360'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Artificial intelligence (AI) is the ability of a computer program or a machine to think and learn. It is also a field of study which tries to make computers \"smart\". They work on their own without being encoded with commands. John McCarthy came up with the name \"Artificial Intelligence\" in 1955. In general use, the term \"artificial intelligence\" means a programme which mimics human cognition. At least some of the things we associate with other minds, such as learning and problem solving can be done by computers, though not in the same way as we do. Andreas Kaplan and Michael Haenlein define AI as a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation. An ideal (perfect) intelligent machine is a flexible agent which perceives its environment and takes actions to maximize its chance of success at some goal or objective. As machines become increasingly capable, mental facu"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'source': 'Wikipedia', 'id': '44742', 'title': 'Artificial neural network'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A neural network (also called an ANN or an artificial neural network) is a sort of computer software, inspired by biological neurons. Biological brains are capable of solving difficult problems, but each neuron is only responsible for solving a very small part of the problem. Similarly, a neural network is made up of cells that work together to produce a desired result, although each individual cell is only responsible for solving a small part of the problem. This is one method for creating artificially intelligent programs. Neural networks are an example of machine learning, where a program can change as it learns to solve a problem. A neural network can be trained and improved with each example, but the larger the neural network, the more examples it needs to perform well—often needing millions or billions of examples in the case of deep learning. There are two ways to think of a neural network. First is like a human brain. Second is like a mathematical equation."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"What is the difference between Transformers (paper - attention all you need) and Vision-Transformers?\"\n",
        "top_docs = similarity_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "IaQ-gxPnVgMy",
        "outputId": "48433240-48ee-4aa6-f82d-6c571f39830f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata : {'total_pages': 22, 'producer': 'pdfTeX-1.40.21', 'creationdate': '2021-06-04T00:19:58+00:00', 'title': '', 'keywords': '', 'author': '', 'page': 7, 'creator': 'LaTeX with hyperref', 'moddate': '2021-06-04T00:19:58+00:00', 'creationDate': 'D:20210604001958Z', 'format': 'PDF 1.5', 'modDate': 'D:20210604001958Z', 'source': '/content/rag_docs/vision_transformer.pdf', 'file_path': '/content/rag_docs/vision_transformer.pdf', 'subject': '', 'trapped': ''}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Published as a conference paper at ICLR 2021\n4.4\nSCALING STUDY\nWe perform a controlled scaling study of different models by evaluating transfer performance from\nJFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\nperformance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\nR50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\nfor 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\nL/16 and H/14 pre-trained for 14 epochs; and 5 hybrids, R50+ViT-B/32, B/16, L/32, L/16 pre-\ntrained for 7 epochs, plus R50+ViT-L/16 pre-trained for 14 epochs (for hybrids, the number at the\nend of the model name stands not for the patch size, but for the total dowsampling ratio in the ResNet\nbackbone).\nFigure 5 contains the transfer performance versus total pre-training compute (see Appendix D.5\nfor details on computational costs). Detailed results per mode"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'title': '', 'author': '', 'trapped': '', 'moddate': '2021-06-04T00:19:58+00:00', 'subject': '', 'keywords': '', 'total_pages': 22, 'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'modDate': 'D:20210604001958Z', 'page': 1, 'format': 'PDF 1.5', 'source': '/content/rag_docs/vision_transformer.pdf', 'creationdate': '2021-06-04T00:19:58+00:00', 'creationDate': 'D:20210604001958Z', 'file_path': '/content/rag_docs/vision_transformer.pdf'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Published as a conference paper at ICLR 2021\ninherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well\nwhen trained on insufﬁcient amounts of data.\nHowever, the picture changes if the models are trained on larger datasets (14M-300M images). We\nﬁnd that large scale training trumps inductive bias. Our Vision Transformer (ViT) attains excellent\nresults when pre-trained at sufﬁcient scale and transferred to tasks with fewer datapoints. When\npre-trained on the public ImageNet-21k dataset or the in-house JFT-300M dataset, ViT approaches\nor beats state of the art on multiple image recognition benchmarks. In particular, the best model\nreaches the accuracy of 88.55% on ImageNet, 90.72% on ImageNet-ReaL, 94.55% on CIFAR-100,\nand 77.63% on the VTAB suite of 19 tasks.\n2\nRELATED WORK\nTransformers were proposed by Vaswani et al. (2017) for machine translation, and have since be-\ncome the state of the art method in many NLP tasks. Large Transformer-based mo"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'page': 0, 'total_pages': 22, 'moddate': '2021-06-04T00:19:58+00:00', 'author': '', 'trapped': '', 'keywords': '', 'title': '', 'file_path': '/content/rag_docs/vision_transformer.pdf', 'subject': '', 'source': '/content/rag_docs/vision_transformer.pdf', 'creationDate': 'D:20210604001958Z', 'creationdate': '2021-06-04T00:19:58+00:00', 'modDate': 'D:20210604001958Z', 'format': 'PDF 1.5'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Published as a conference paper at ICLR 2021\nAN IMAGE IS WORTH 16X16 WORDS:\nTRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\nAlexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\nXiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\nGeorg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n∗equal technical contribution, †equal advising\nGoogle Research, Brain Team\n{adosovitskiy, neilhoulsby}@google.com\nABSTRACT\nWhile the Transformer architecture has become the de-facto standard for natural\nlanguage processing tasks, its applications to computer vision remain limited. In\nvision, attention is either applied in conjunction with convolutional networks, or\nused to replace certain components of convolutional networks while keeping their\noverall structure in place. We show that this reliance on CNNs is not necessary\nand a pure transformer applied directly to sequences of image patches can perform\nvery well on image classiﬁcation tasks. When pre-traine"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'subject': '', 'producer': 'pdfTeX-1.40.21', 'moddate': '2021-06-04T00:19:58+00:00', 'format': 'PDF 1.5', 'total_pages': 22, 'creationDate': 'D:20210604001958Z', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-06-04T00:19:58+00:00', 'file_path': '/content/rag_docs/vision_transformer.pdf', 'trapped': '', 'page': 3, 'keywords': '', 'modDate': 'D:20210604001958Z', 'author': '', 'title': '', 'source': '/content/rag_docs/vision_transformer.pdf'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Published as a conference paper at ICLR 2021\nThe MLP contains two layers with a GELU non-linearity.\nz0 = [xclass; x1\npE; x2\npE; · · · ; xN\np E] + Epos,\nE ∈R(P 2·C)×D, Epos ∈R(N+1)×D\n(1)\nz′\nℓ= MSA(LN(zℓ−1)) + zℓ−1,\nℓ= 1 . . . L\n(2)\nzℓ= MLP(LN(z′\nℓ)) + z′\nℓ,\nℓ= 1 . . . L\n(3)\ny = LN(z0\nL)\n(4)\nInductive bias.\nWe note that Vision Transformer has much less image-speciﬁc inductive bias than\nCNNs. In CNNs, locality, two-dimensional neighborhood structure, and translation equivariance are\nbaked into each layer throughout the whole model. In ViT, only MLP layers are local and transla-\ntionally equivariant, while the self-attention layers are global. The two-dimensional neighborhood\nstructure is used very sparingly: in the beginning of the model by cutting the image into patches and\nat ﬁne-tuning time for adjusting the position embeddings for images of different resolution (as de-\nscribed below). Other than that, the position embeddings at initialization time carry no information\nabout the 2D pos"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'moddate': '2021-06-04T00:19:58+00:00', 'creationDate': 'D:20210604001958Z', 'subject': '', 'total_pages': 22, 'modDate': 'D:20210604001958Z', 'creationdate': '2021-06-04T00:19:58+00:00', 'keywords': '', 'creator': 'LaTeX with hyperref', 'source': '/content/rag_docs/vision_transformer.pdf', 'page': 4, 'file_path': '/content/rag_docs/vision_transformer.pdf', 'trapped': '', 'producer': 'pdfTeX-1.40.21', 'author': '', 'title': '', 'format': 'PDF 1.5'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Published as a conference paper at ICLR 2021\nModel\nLayers\nHidden size D\nMLP size\nHeads\nParams\nViT-Base\n12\n768\n3072\n12\n86M\nViT-Large\n24\n1024\n4096\n16\n307M\nViT-Huge\n32\n1280\n5120\n16\n632M\nTable 1: Details of Vision Transformer model variants.\nWe also evaluate on the 19-task VTAB classiﬁcation suite (Zhai et al., 2019b). VTAB evaluates\nlow-data transfer to diverse tasks, using 1 000 training examples per task. The tasks are divided into\nthree groups: Natural – tasks like the above, Pets, CIFAR, etc. Specialized – medical and satellite\nimagery, and Structured – tasks that require geometric understanding like localization.\nModel Variants. We base ViT conﬁgurations on those used for BERT (Devlin et al., 2019), as\nsummarized in Table 1. The “Base” and “Large” models are directly adopted from BERT and we\nadd the larger “Huge” model. In what follows we use brief notation to indicate the model size and\nthe input patch size: for instance, ViT-L/16 means the “Large” variant with 16×16 input patch siz"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"Who is Nilotpal?\"\n",
        "top_docs = similarity_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "raKjm3VwVgPu",
        "outputId": "130e57f2-11c3-4c98-c212-c75def4160bd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata : {'source': 'Wikipedia', 'id': '623001', 'title': 'Pratidaan'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Pratidaan (); is a Bengali television Popular Soap Opera that premiered on August 21, 2017 and airs on STAR Jalsha. Produced by Boyhood Productions, it stars Sandipta Sen and Sheikh Rezwan Rabbani in lead roles and Tanuka Chatterjee in a Negative role. It replaced Star Jalsha's popular show \"Milon Tithi\". Shimul is a very well educated girl and she wants to pursue her study further. She wants to get married in a family where she gets her due respect as a highly educated girl. But on the other hand her would be mother-in-law wants to get a bride who is altoegther illiterate. As the destiny had it her son meets Shimul, a girl of diametrically opposite character. They get married and she will have to teach life lessons to her arrogant husband, Neel, was not the kind of marriage Shimul was hoping for. Will they ever fall in love? What happens next? http://www.newstechcafe.com/2017/07/protidan-serial-on-star-jalsha-tv-plot.html"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'title': 'Tapas Paul', 'id': '739002', 'source': 'Wikipedia'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Tapas Paul (29 September 1958 – 18 February 2020) was an Indian actor and politician. He is known for acting in \"Dadar Kirti\", \"Bhalobasa Bhalobasa\", \"Anurager Choyan\", \"Amar Bandhan\", \"Guru Dakshina\", \"Uttara\" and \"Mondo Meyer Upakhyan\". Outside of acting, he served as an MLA (2001–2009) and an MP (2009–2019). Paul was born in Chandannagar, West Bengal. On 18 February 2020, he died due to cardiac arrest in Mumbai, Maharastra. He was 61."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'source': 'Wikipedia', 'title': 'Nils John Nilsson', 'id': '692744'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Nils John Nilsson (February 6, 1933 – April 23, 2019) was an American computer scientist. He was one of the founding researchers in the ideas of artificial intelligence. He was born in Saginaw, Michigan. He was the first Kumagai Professor of Engineering in computer science at Stanford University from 1991 until his retirement. His best known work was Shakey the robot. Nilsson died on April 23, 2019, at his home in Medford, Oregon, at the age of 86."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'source': 'Wikipedia', 'id': '798128', 'title': 'Mimlu Sen'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Mimlu Sen (born 1949) is an Indian author, translator, musician, composer and producer. Sen was born in Shillong, Meghalaya, India. During the 1960s and 1970s she studying in Kolkata and participating in street protests demanding an end of Vietnam War. She has been jailed for Naxalite movement. Sen was published her first book \"Baulsphere\" in 2009. The following year it was published as \"The Honey Gatherers\". Piers Moore Ede stated that \"The Honey Gatherers\" recounts Sen's adventures in rural Bengal."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata : {'title': 'Amloki', 'source': 'Wikipedia', 'id': '620477'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Amloki (); is a Bengali television soap opera that premiered on 12 February 2018 and airs on Zee Bangla. It Replaced Zee Bangla's Popular Show Stree. The Show Stars Aishwarya Roy and Antara as The Main Female Protagonists and Indrajit Bose as The Main Male Antagonist and bhaswar chatterjee as the male lead.The show will go off air on 30th November 2018 and will get replaced byRanu Pelo Lottery. It narrates the story of a six-year-old girl named Amloki, who was born deaf and dumb. Amloki hails from a poor family. Her father,Ratan is a gambler and steals jewelry while her mother runs the family by preparing jaggery at daytime and acting in Jatra at night. The sole reason for her mother’s existence is Amloki. She believes that someday her daughter will be cured. However, destiny has its own plans. Amloki loses her mother suddenly."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Augmentation Part (Enhanced prompt)"
      ],
      "metadata": {
        "id": "_WMPW-fxYJbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "rag_prompt = \"\"\"\n",
        "You are an assistant specialized in question answering and translation.\n",
        "Your task is to respond to the given question using only the information provided in the retrieved context.\n",
        "\n",
        "Instructions:\n",
        "- If the answer is not present in the context, clearly state: \"I don’t know based on the given context.\"\n",
        "- Do not invent or assume any information.\n",
        "- Write the answer in clear, simple language with correct grammar.\n",
        "- Make the response detailed, structured, and easy to understand.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "oIlZEnwTYONP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
      ],
      "metadata": {
        "id": "mJlpdKo_YOQg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# last part - LLM and Generation part"
      ],
      "metadata": {
        "id": "rsa-aYYkZs-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "qa_rag_chain = (\n",
        "    {\"context\":(similarity_retriever | format_docs),\n",
        "     \"question\": RunnablePassthrough()} | rag_prompt_template | chatgpt\n",
        ")"
      ],
      "metadata": {
        "id": "1uQnoFWuYOTo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"What is Machine Learning?, please explain in a simple language so that any non-tech background can understand?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "i5twZFu1YOWt",
        "outputId": "74dc573a-796a-4705-d550-605a24f19d6d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Machine learning is a part of computer science that allows computers to learn from data without being specifically programmed for each task. This means computers can improve their performance on a task by learning from previous experiences and data inputs. \n\nHere's a simple breakdown of how it works:\n\n1. **Learning from Data**: Instead of giving the computer explicit instructions, we provide it with examples or data. The computer then analyzes this data to find patterns and make predictions.\n\n2. **Algorithms**: These are the instructions that guide the computer in learning from the data. They can create a model that helps the computer understand the patterns in the data it has received.\n\n3. **Applications**: Machine learning is used in various real-world situations, like filtering spam emails, recognizing images or characters, and improving search engines. \n\n4. **Deep Learning**: This is a more advanced type of machine learning that uses complex structures called neural networks. It helps computers perform challenging tasks, like understanding speech or recognizing images, by processing information through multiple layers that gradually abstract the data.\n\n5. **Types of Learning**: There are different ways machine learning can occur, including supervised learning where the computer is taught with examples that have known outcomes, and unsupervised learning where the computer has to find patterns in data without any prior knowledge.\n\nOverall, machine learning helps computers to \"learn\" from data and make better decisions or predictions based on that learning."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"What is Machine Learning?, please explain in a simple hindi language so that any non-tech background can understand?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "W-nsoLrIbDHy",
        "outputId": "3a4a0675-6547-4ec3-9176-980ea14e3005"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Machine Learning (मशीन लर्निंग) एक ऐसा क्षेत्र है जो कंप्यूटरों को बिना अधिक निर्देश दिए सीखने की क्षमता देता है। इसे कंप्यूटर विज्ञान (computer science) का एक उपक्षेत्र (subfield) माना जाता है। मशीन लर्निंग का विचार आर्टिफिशियल इंटेलिजेंस (Artificial Intelligence) से आया है। इसमें ऐसे एल्गोरिदम (algorithms) का अध्ययन और निर्माण किया जाता है, जो डेटा पर सीख सकते हैं और भविष्यवाणियाँ (predictions) कर सकते हैं।\n\nमशीन लर्निंग का मतलब है कि कंप्यूटर कार्यक्रमित निर्देशों का पालन करते हुए, डेटा के आधार पर नई भविष्यवाणियाँ या निर्णय ले सकते हैं। उदाहरण के लिए, ई-मेल में स्पैम फ़िल्टरिंग, नेटवर्क में अनधिकृत व्यक्तियों का पता लगाना, और तस्वीरों को पहचानना जैसी गतिविधियाँ मशीन लर्निंग का हिस्सा हैं। इसका उपयोग तब किया जाता है जब पारंपरिक तरीकों से स्पष्ट एल्गोरिदम बनाना संभव नहीं होता।\n\nमशीन लर्निंग के कई प्रकार होते हैं, जिनमें से एक है \"डीप लर्निंग\" (Deep Learning)। यह विशेष प्रकार के न्यूरल नेटवर्क (Neural Networks) के साथ काम करता है। न्यूरल नेटवर्क एक तरह का सॉफ्टवेयर है, जो जैविक न्यूरॉन्स से प्रेरित है और जो एक साथ मिलकर किसी समस्या का समाधान करता है। \n\nसामान्यत: मशीन लर्निंग में दो प्रकार की तकनीकें होती हैं: \"सुपरवाइज्ड लर्निंग\" (Supervised Learning) और \"अनसुपरवाइज्ड लर्निंग\" (Unsupervised Learning)। सुपरवाइज्ड लर्निंग में, सिस्टम को पहले से दिए गए लेबल डेटा से सीखना होता है। \n\nइस तरह, मशीन लर्निंग वह प्रक्रिया है जो कंप्यूटरों को खुद से सुधारने और सीखने की क्षमता देती है, ताकि वे अधिक सटीकता के साथ काम कर सकें।"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"Who is Nilotpal?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "DLqNspAcbDK_",
        "outputId": "47436ff3-6433-446d-b187-468b26ca89a3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I don’t know based on the given context."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"what is CNN and ComputerVision? please explain in a simple language with example so that layman can also understand and also provide response in Tamil, Telugu, Hindi, Bengali and Gujarati Language?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "x9WzwgKwbDOM",
        "outputId": "48e63eae-479c-42f1-e927-f57e679e8e8c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**What is CNN and Computer Vision?**\n\n**CNN (Convolutional Neural Network):**\nCNN is a type of artificial intelligence model that is particularly good at recognizing patterns in images. It mimics the way our brain works to understand visual data. For example, if you show a CNN a picture of a cat, it can learn to identify the features that make it look like a cat (like ears, whiskers, and fur texture) and then tell you if a new picture is also a cat or not. \n\nTo put it simply, think of CNN as a smart computer program that learns to see images just like humans do. It processes images using layers of artificial neurons that each focus on different details of the image, which helps it understand what the image is about.\n\n**Computer Vision:**\nComputer Vision is the field that focuses on enabling machines to interpret and understand visual information from the world. It involves using algorithms to process images and videos, allowing computers to \"see\" and analyze visual data. \n\nFor instance, when you use a smartphone to unlock it with your face, that's computer vision at work. The phone's camera takes a picture of your face, and the software recognizes and matches it against stored images to confirm your identity.\n\n### Translations:\n\n**Tamil:**\n**CNN (கோவுன்லூஷனல் நர்வல் நெட்‌வர்க்):**\nCNN என்பது புகைப்படங்களில் உள்ள மாதிரிகளை அடையாளம் காண மிகவும் சிறந்த செயற்கை நுண்ணறிவு மாதிரியே ஆகும். இது பார்வை தரவுகளை புரிந்து கொள்ள எங்களின் மூளை செயல்படும் வழியை நகலெடுக்கிறது. எடுத்துக்காட்டு, நீங்கள் CNN க்கு ஒரு பூனைக்கான புகைப்படத்தை காட்டின், அது அந்த பூனை போல உள்ள அம்சங்களை (சேப்புகள், வெள்ளி மற்றும் உறையும் உருக்) அடையாளம் கண்டுதான், புதிய புகைப்படம் பூனை தான் என்று உனக்கு சொல்கிறது.\n\n**கணினி பார்வை:**\nகணினி பார்வை என்பது இயந்திரங்கள் உலகில் உள்ள பார்வை தகவல்களை விளக்க மற்றும் புரிந்து கொள்ள உதவுகிறது. இப்போது, கணினிகள் \"பார்க்க\" மற்றும் பார்வை தரவுகளை பகுப்பாய்வு செய்ய ஆல்கோரதங்களைப் பயன்படுத்துகிறது. எடுத்துக்காட்டு, நீங்கள் உங்கள் முகத்துடன் ஸ்மார்ட்போனை கண்காணிக்க பயன்படுகின்றீர்கள்.\n\n---\n\n**Telugu:**\n**CNN (కన్వోల్యూషనల్ న్యూరల్ నెట్‌వర్క్):**\nCNN అనేది చిత్రం ప్యాటర్న్‌లను గుర్తించడానికి చాలా మంచి యంత్రం. ఇది మన నాళికల వలె పనిచేస్తుంది. ఉదాహరణకు, మీరు CNN కి కుక్క యొక్క చిత్రాన్ని చూపిస్తే, అది కుక్కకు సంబంధించిన ఆకారాలు (చేవి, ముక్కు, తోలు) గుర్తించగలదు.\n\n**కంప్యూటర్ విజన్:**\nకంప్యూటర్ విజన్ అనేది యంత్రాలకు ప్రపంచంలో ఉన్న దృశ్య సమాచారాన్ని అర్థం చేసుకోవటానికి ఉపయోగించే పద్ధతులు. ఉదాహరణకు, మీరు మీ ముఖాన్ని చూపించి మీ ఫోన్‌ను మొదలి గ్రీన్ చేస్తే, అది కంప్యూటర్ విజన్ వలన ఏర్పడుతోంది.\n\n---\n\n**Hindi:**\n**CNN (कन्वोल्यूशनल न्यूरल नेटवर्क):**\nCNN एक तरह का कृत्रिम बुद्धिमत्ता मॉडल है जो चित्रों में पैटर्न पहचानने में बहुत अच्छा है। यह हमारे मस्तिष्क की तरह काम करता है। उदाहरण के लिए, यदि आप CNN को एक बिल्ली की तस्वीर दिखाते हैं, तो यह पहचान सकता है कि इसमें क्या विशेषताएं हैं (जैसे कान, मूंछें, और फर की बनावट) और फिर बताना कि क्या एक नई तस्वीर भी बिल्ली है या नहीं।\n\n**कंप्यूटर विज़न:**\nकंप्यूटर विज़न वह क्षेत्र है जो मशीनों को दृश्य जानकारी की व्याख्या और समझने में सक्षम बनाता है। उदाहरण के लिए, जब आप अपने चेहरे के साथ स्मार्टफोन को अनलॉक करते हैं, तो यह कंप्यूटर विज़न का उपयोग कर रहा है।\n\n---\n\n**Bengali:**\n**CNN (কনভলিউশাল নিউরাল নেটওয়ার্ক):**\nCNN হল একটি কৃত্রিম বুদ্ধিমত্তার পদ্ধতি যা চিত্রে নিদর্শন চিহ্নিত করতে খুব দক্ষ। এটি আমাদের মস্তিষ্কের কাজ করার পদ্ধতির অনুকরণ করে। উদাহরণস্বরূপ, আপনি যদি CNN-কে একটি বিড়ালের ছবি দেখান তবে এটি ছবিটি বিড়াল কিনা তা বোঝার জন্য বৈশিষ্ট্যগুলি চিহ্নিত করতে পারে।\n\n**কম্পিউটার ভিশন:**\nকম্পিউটার ভিশন হল সেই ক্ষেত্র যা যন্ত্রগুলিকে দৃষ্টি তথ্য ব্যাখ্যা এবং বুঝতে সক্ষম করে। উদাহরণস্বরূপ, যখন আপনি আপনার মুখ দিয়ে স্মার্টফোন আনলক করেন, তখন এটি কম্পিউটার ভিশনের কাজ করছে।\n\n---\n\n**Gujarati:**\n**CNN (કન્વોલ્યુશનલ ન્યૂરલ નેટવર્ક):**\nCNN એ એક પ્રકારની આર્ટિફિશ્યલ ઇન્ટેલિજન્સ મોડેલ છે જે ચિત્રોમાં પેટર્ન માન્ય કરવા માટે ખૂબ સારી છે. તે આપણા મગજની કામગીરીને અનુરૂપ છે. ઉદાહરણ તરીકે, જો તમે CNN ને એક બિલાડીનું છબી દર્શાવશો તો તે તેમાંથી બિલાડીની ખાસિયતો (કાન, મૂંછ અને વાળ) ઓળખી શકે છે.\n\n**કમ્પ્યુટર વિઝન:**\nકમ્પ્યુટર વિઝન એ ક્ષેત્ર છે જે મશીનોને વર્તમાન visual ડેટાને વ્યાખ્યાયિત કરવા અને સમજીને અસરો બનાવે છે. ઉદાહરણ તરીકે, જ્યારે તમે તમારા ચહેરા સાથે સ્માર્ટફોનને અનલોક કરતા છો, ત્યારે તે કમ્પ્યુટર વિઝન છે."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"Who is Narendra Modi in India?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "display(Markdown(result.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "cxbNzn4ybDRm",
        "outputId": "1a95ac40-e465-4a6b-f985-344913ad4fd2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I don’t know based on the given context."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfGkkdnqdL88"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}